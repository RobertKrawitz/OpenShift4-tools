#!/usr/bin/env python3

# Copyright 2021 Robert Krawitz/Red Hat
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function
from prometheus_api_client import PrometheusConnect
import argparse
import datetime
import json
import openshift
import selectors
import subprocess
import sys
import time
import urllib3
import uuid
import yaml


def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


def efail(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)
    sys.exit(1)


def run_command(cmd, fail_on_bad_status=True, report_stderr_async=True,
                report_stdout_async=False):
    """ Run specified command, capturing stdout and stderr as array of timestamped lines.
        Optionally fail if return status is non-zero.  Also optionally report
        stdout and/or stderr to the appropriate file descriptors
    """
    with subprocess.Popen(cmd, stdin=subprocess.DEVNULL, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as command:
        stdout_data = []
        stderr_data = []

        sel = selectors.DefaultSelector()
        sel.register(command.stdout, selectors.EVENT_READ)
        sel.register(command.stderr, selectors.EVENT_READ)
        while True:
            # Keep reading until we reach EOF on both channels.
            # command.poll() is not a good criterion because the process
            # might complete before everything has been read.
            foundSomething = False
            for key, _ in sel.select():
                data = key.fileobj.readline()
                if len(data) > 0:
                    foundSomething = True
                    data = data.decode().rstrip()
                    if key.fileobj is command.stdout:
                        stdout_data.append([time.time(), data])
                        if report_stdout_async:
                            print(data)
                    elif key.fileobj is command.stderr:
                        stderr_data.append([time.time(), data])
                        if report_stderr_async:
                            print(data, file=sys.stderr)
            if not foundSomething:
                while command.poll() is None:
                    time.sleep(1)
                if fail_on_bad_status and command.poll() != 0:
                    raise RuntimeError('Command %s failed: exit status %d' % (' '.join(cmd), command.poll()))
                return (stdout_data, stderr_data, command.poll())


def run_command_simple(cmd):
    stdout, _, _ = run_command(cmd)
    return "\n".join(a[1] for a in stdout)


def get_prometheus_default_url():
    try:
        with openshift.project('openshift-monitoring'):
            return 'https://%s' % openshift.selector(['route/prometheus-k8s']).objects()[0].as_dict()['spec']['host']
    except Exception as err:
        efail("Unable to retrieve prometheus-k8s route: %s" % err)


def get_prometheus_token():
    # Unfortunately, the openshift package doesn't appear to provide the
    # necessary primitives to do this.
    try:
        return 'Bearer %s' % run_command_simple(['oc', 'sa', 'get-token',
                                                 '-n', 'openshift-monitoring',
                                                 'prometheus-k8s'])
    except Exception as err:
        efail("Unable to retrieve prometheus-k8s token: %s" % err)


def get_cluster_version():
    try:
        return json.loads(run_command_simple(['oc', 'version', '-ojson']))
    except Exception as err:
        efail("Unable to retrieve cluster version: %s" % err)


def get_nodes():
    try:
        return json.loads(run_command_simple(['oc', 'get', 'nodes', '-ojson']))
    except Exception as err:
        efail("Unable to retrieve cluster version: %s" % err)


def generate_uuid():
    UUID = uuid.uuid4()
    print('UUID: %s' % UUID, file=sys.stderr)
    return str(UUID)


parser = argparse.ArgumentParser(description='Scrape data from Prometheus')
parser.add_argument('-u', '--url', '--prometheus-url', type=str,
                    help='Prometheus URL', metavar='URL',
                    default=get_prometheus_default_url())
parser.add_argument('-s', '--step', type=int, default=30, metavar='seconds',
                    help='Step duration')
parser.add_argument('-t', '--token', type=str,
                    help='Prometheus authentication token', metavar='token',
                    default=get_prometheus_token())
parser.add_argument('-m', '--metrics-profile', type=str, metavar='file',
                    help='Metrics profile file or URL', default='metrics.yaml')
parser.add_argument('-j', '--json-output', help='Print JSON formatted output',
                    action='store_true')
parser.add_argument('--epoch', type=int, default=1200, metavar='seconds',
                    help='Start of metrics relative to job start')
parser.add_argument('--post-settling-time', type=int, default=60, metavar='seconds',
                    help='Time to continue collecting metrics after job completion')
parser.add_argument('--json-from-command', action='store_true',
                    help='Interpret command stdout as JSON')
parser.add_argument('--uuid', type=str, metavar='UUID', default=generate_uuid(),
                    help='Index results by UUID (generate if not provided)'),
parser.add_argument('command', metavar='command', help='command [args...]',
                    type=str, nargs='*')
args = parser.parse_args()


urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
authorization = {}

if args.token != '':
    authorization['Authorization'] = args.token

prom = PrometheusConnect(url=args.url, disable_ssl=True, headers=authorization)

try:
    with open(args.metrics_profile, 'r') as metrics_yaml:
        yaml = yaml.safe_load(metrics_yaml)
except FileNotFoundError as err:
    efail('Cannot open metrics profile: %s' % err)
    sys.exit(1)

startTime = int(time.time())
metricsStartTime = datetime.datetime.now() + datetime.timedelta(seconds=-abs(args.epoch))
chunkSize = datetime.timedelta(seconds=args.step)
stdout_data = []
stderr_data = []

try:
    stdout_data, stderr_data, cmd_exit_status = run_command(args.command)
except Exception as err:
    efail(err)
endTime = int(time.time())

json_output = None
if args.json_from_command and len(stdout_data) > 0:
    try:
        json_output = json.loads("\n".join(a[1] for a in stdout_data))
    except json.decoder.JSONDecodeError as err:
        eprint("Cannot decode command output as JSON: %s" % err)

time.sleep(args.post_settling_time)
metricsEndTime = datetime.datetime.now()

metric_results = {}

for metric in yaml['metrics']:
    metric_data = []
    if 'instant' not in metric or metric['instant'] is not True:
        metric_data = prom.custom_query_range(metric['query'], start_time=metricsStartTime, end_time=metricsEndTime, step=30)
    else:
        metric_data = prom.custom_query(metric['query'])
    name = metric['query']
    if 'metricName' in metric:
        name = metric['metricName']
    metric_results[name] = {
        'query': metric['query'],
        'name': name,
        'data': metric_data
    }

results = {
    'metadata': {
        'jobStart': startTime,
        'jobEnd': endTime,
        'uuid': args.uuid,
        'cluster_version': get_cluster_version(),
        'nodes': [n.as_dict() for n in openshift.selector('nodes').objects()]
    },
    'command': args.command,
    'stdout': stdout_data,
    'stderr': stderr_data,
    'metrics': metric_results,
}

if json is not None:
    results['results'] = json_output

print(json.dumps(results, indent=4))
