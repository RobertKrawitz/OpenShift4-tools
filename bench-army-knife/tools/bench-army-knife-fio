#!/bin/bash

# Copyright 2020 Robert Krawitz/Red Hat
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

function fatal() {
    echo "FATAL: $*" 1>&2
    exit 1
}

function debug() {
    if (( debug )) ; then
	echo "DEBUG: $*" 1>&2
    fi
}

# Find our helpers
function finddir() {
    local path_to_file
    path_to_file=$(readlink -f "$0")
    if [[ -z $path_to_file ]] ; then
	return 1
    elif [[ -d $path_to_file ]] ; then
	echo "$path_to_file/"
    elif [[ -e $path_to_file ]] ; then
	echo "${path_to_file%/*}/"
    else
	return 1
    fi
    return 0
}

declare ___realsc=
declare ___topsc
set -u
if [[ -z ${___topsc:-} ]] ; then
    export ___topsc="${0##*/}"
    # shellcheck disable=SC2155
    export ___topdir="$(finddir "$0")"
    [[ -z $___topdir ]] && fatal "Can't find directory for $0"
fi

function clean_startup() {
    [[ -f $___realsc ]] && rm -f "$___realsc"
}

# This allows us to edit the script while another instance is running
# since this script sticks around until the user exits the spawned shell.
# It's fine for the running script to be removed, since the shell still
# has its open file descriptor.
if [[ $# = 0 || $1 != "--DoIt=$0" ]] ; then
    tmpsc=$(mktemp -t "${___topsc}".XXXXXXXXXX)
    [[ -z $tmpsc || ! -f $tmpsc || -L $tmpsc ]] && fatal "Can't create temporary script file"
    trap clean_startup EXIT SIGHUP SIGINT SIGQUIT SIGTERM
    PATH+=${PATH:+:}$___topdir
    cat "$0" > "$tmpsc"
    chmod +x "$tmpsc"
    exec "$tmpsc" "--DoIt=$tmpsc" "$@"
else
    ___realsc=${1#--DoIt=}
    clean_startup
    shift
fi

echo "Command: ${___topsc:-$0} $*" 1>&2

declare namespace=pbench
declare -i kata=0
declare -i initialize_ns=0
declare -i port=30666
declare -i ssh_port=30222
declare -i redis_port=17001	# for tool-meister
declare -i datasink_port=8080	# For tool data sink
declare kataname=non_kata
declare username=$LOGNAME
declare configname=
declare -i controller_anti_affinity=1
declare -i host_networking=0
declare -i print_only=0
declare -i quiet=0
declare -i instances=1
declare -i force_privileged=0
# shellcheck disable=SC2155
declare hostname=$(hostname --fqdn)
declare -a affinity_types=(podAffinity podAntiAffinity)
declare pbench_agent_cfg=
declare pbench_private_key=
declare pbench_agent_key=
declare pbench_controller_bin=/usr/local/bin/run-pbench-controller
declare pbench_agent_container_bin=/usr/local/bin/run-pbench-agent-container
declare -a additional_files=()
declare selector_key=bench-army-knife-agent
declare pod_cpu_request=
declare pod_cpu_limit=
declare pod_memory_request=
declare pod_memory_limit=
declare -i force_external_agents=-1
declare interface=
declare -i waitforever=0
declare -A extra_hosts=()
declare pbench_send_results=-r
declare -r report_file=/tmp/pbench-report.json
# shellcheck disable=SC2155
declare job_uuid=$(uuidgen -r)
declare pre_script=
declare secret_name=credentials
declare secret_root=/etc/$secret_name
declare -i report_full_timeseries_data=1
declare -i debug=0
declare report_data=${_BENCH_ARMY_KNIFE_EXTRACT_DATA:-0}

# Benchmark-specific variables
declare -r bm_name=fio
declare -i anti_affinity=0
declare pbench_tunnel_bin=/usr/local/bin/create-tunnel
declare pvname=
declare pvtype=
declare pvtype_key=
declare pvscoped_name=
declare pvmount_path=
# This is used inside a here document, which shellcheck can't see
# shellcheck disable=SC2034
declare job_file=
declare jobfile=

function usage() {
    [[ -n "$*" ]] && echo "Unknown option $*" 1>&2
    expand 1>&2 <<EOF
Usage: ${___topsc:-$0} [options] [-- pbench-${bm_name} args]
       -A agent_key   Use the specified public/private key pair for
                      communication with the agent.  Session key will
                      be generated if not provided.
       -C name        Use the specified name for the controller's hostname
       -c configname  Record the specified configuration name
       -D             Enable debugging.
       -d             Enable data collection and reporting.
       -E             Don't use external agents on worker nodes.
                      Default with non-Kata pods
       -e             Use external agents on the worker nodes.
                      Default yes with Kata pods
       -F file        Add the specified file to the secret passed to
                      the pods.  May be <file> or <name=file>.
       -f             Force all containers to be privileged.
                      Normally kata containers are not.  For this to work
                      on kata, it's necessary to add
                      privileged_without_host_devices = true
                      to the [crio.runtime.runtimes.kata] stanza in
                      /etc/crio/crio.conf.d/50-kata.conf.
       -H             Use host networking in worker pods
       -I             Initialize the desired namespace
       -i interface   Use the specified network interface on each pod.
                      Default is the default interface.
       -J jobfile     Use the specified fio job file as the template.
       -K             Use kata containers
       -k keyfile     Use the specified private key for sending results.
                      No default; must be provided.
       -L cpu_limit   Pod CPU limit
       -M mem_limit   Pod memory limit
       -m mem_request Pod memory request
       -N namespace   Use the specified namespace (default $namespace)
       -n             Don't actually do anything
       -P pbench_cfg  Use the specified pbench-agent.cfg file.
                      No default; must be provided.
       -p pods        Number of pods to create
       -q             Don't emit agent logs on stderr
       -r pre-script  Run the specified pre-script prior to invoking
                      the controller.  All args to the pre-script
                      should then be exec'ed as the next stage.
       -R cpu_request Pod CPU request
       -s             Send rather than move Pbench results
       -T             Report only summary
       -u user        Record the specified username
       -V volume_spec Mount a specified volume
                      spec is name:type:path:type_key:scoped_name
                      name is the name of the volume (required).
                      type is the type of volume (required).
                      mount_path is the path on which to mount the volume
                          (required).
                      type_key is the key for the volume (e. g.
                          claimName for persistentVolumeClaim)
                      scoped_name is the volume's name as recognized
                          by the description (required).
       -w             Agent and client wait forever at end
       -X             Affinity between ${bm_name} pods (default)
       -x             Anti-affinity between ${bm_name} pods
       -Y             Affinity between pbench controller and ${bm_name}
       -y             Anti-affinity between pbench controller and ${bm_name}
                      (default).
EOF
    exit 1
}

while getopts 'A:C:c:DdEeF:fHIi:J:Kk:L:M:m:N:nP:p:qR:r:SsTu:V:wXxYy' opt ; do
    case "$opt" in
	A) pbench_agent_key=$OPTARG	 ;;
	C) hostname=$OPTARG		 ;;
	c) configname=$OPTARG		 ;;
	D) debug=1			 ;;
	d) report_data=1		 ;;
	E) force_external_agents=1	 ;;
	e) force_external_agents=0	 ;;
	F) additional_files+=("$OPTARG") ;;
	f) force_privileged=1		 ;;
	H) host_networking=1
	   # shellcheck disable=SC2034
	   hostnetworkname=-hostnetwork	 ;;
	i) interface="$OPTARG"		 ;;
	I) initialize_ns=1		 ;;
	J) jobfile=$OPTARG		 ;;
	K) kata=1
	   kataname=kata		 ;;
	k) pbench_private_key=$OPTARG	 ;;
	L) pod_cpu_limit=$OPTARG	 ;;
	M) pod_memory_limit=$OPTARG	 ;;
	m) pod_memory_request=$OPTARG	 ;;
	N) namespace=$OPTARG		 ;;
	n) print_only=1			 ;;
	P) pbench_agent_cfg=$OPTARG	 ;;
	p) instances=$OPTARG		 ;;
	q) quiet=1			 ;;
	R) pod_cpu_request=$OPTARG	 ;;
	r) pre_script=$OPTARG		 ;;
	S) pbench_send_results=-R	 ;;
	s) pbench_send_results=-r	 ;;
	T) report_full_timeseries_data=0 ;;
	u) username=$OPTARG		 ;;
	V)
	    IFS=':' read -r pvname pvtype pvmount_path pvtype_key pvscoped_name <<< "$OPTARG"
	    if [[ -z "${pvname:-}" || -z "${pvtype:-}" || -z "${pvmount_path:-}" ]] ; then
		echo "name, type, and mount path must be provided for volumes" 1>&2
		exit 1
	    fi
	    ;;
	w) waitforever=1		 ;;
	x) anti_affinity=1		 ;;
	X) anti_affinity=0		 ;;
	y) controller_anti_affinity=1	 ;;
	Y) controller_anti_affinity=0	 ;;
	*) usage "$opt"			 ;;
    esac
done

declare -i error=0
# So we don't inadvertently do something
if (( print_only )) ; then
    export KUBECONFIG=/dev/null
fi
if [[ -z "${pbench_agent_cfg:-}" ]] ; then
    echo "pbench_agent.cfg file not provided" 1>&2
    error=1
elif [[ ! -r "${pbench_agent_cfg:-}" ]] ; then
    echo "Cannot read pbench agent config $pbench_agent_cfg" 1>&2
    error=1
fi
if [[ -z "${pbench_private_key:-}" ]] ; then
    echo "pbench private key file not provided" 1>&2
    error=1
elif [[ ! -r "$pbench_private_key" ]] ; then
    echo "Cannot read pbench private key $pbench_private_key" 1>&2
    error=1
fi
if [[ -n "${pbench_agent_key:-}" && (! -r "$pbench_agent_key" || ! -r "${pbench_agent_key}.pub") ]] ; then
    echo "Cannot read agent key $pbench_agent_key or ${pbench_agent_key}.pub" 1>&2
    error=1
fi

if [[ -n "${pre_script:-}" ]] ; then
    if [[ ! -r "$pre_script" ]] ; then
	echo "Pre-script '$pre_script' does not exist" 1>&2
	error=1
    else
	additional_files+=("$pre_script")
    fi
fi

if [[ -n "${jobfile:-}" ]] ; then
    if [[ ! -r "$jobfile" ]] ; then
	echo "Job file '$jobfile' does not exist" 1>&2
	error=1
    else
	additional_files+=("$jobfile")
    fi
fi

(( error )) && usage

for f in "${additional_files[@]}" ; do
    if [[ $f = "run-pbench-controller="* || $f = "run-pbench-controller" ||
	      $f = *"/run-pbench-controller" ]] ; then
	pbench_controller_bin="$secret_root"/run-pbench-controller
    fi
    if [[ $f = "run-pbench-agent-container="* || $f = "run-pbench-agent-container" ||
	      $f = *"/run-pbench-agent-container" ]] ; then
	pbench_agent_container_bin="$secret_root"/run-pbench-agent-container
    fi
done

configname=${configname:-${bm_name}}-${kataname}-${affinity_types[$anti_affinity],,}${pod_cpu_limit:+-limit-${pod_cpu_limit}}${pod_cpu_request:+-request-${pod_cpu_request}}${pod_memory_limit:+-mlimit-${pod_memory_limit}}${pod_memory_request:+-mrequest-${pod_memory_request}}

shift $((OPTIND-1))

declare -a benchmark_args=("$@")

set -e

function _oc() {
    if (( print_only )) ; then
	echo "+++" oc "$*" 1>&2
	if [[ ($1 = apply || $1 = create) && $2 = '-f' && $3 = '-' ]] ; then
	    expand | grep . 1>&2
	fi
    else
	oc "$@" 1>&2
    fi
}

function get_ip() {
    local netname=$1; shift
    if oc get pod "$@" >/dev/null 2>&1 ; then
	if [[ -n "${interface:-}" ]] ; then
	    # Note that because pod annotations are strings rather than JSON
	    # objects we have to use one jq invocation to print the annotation
	    # raw, which will look like JSON (we hope) piped into another
	    # invocation
	    oc get pod -ojson "$@" | jq -r '.metadata.annotations."k8s.v1.cni.cncf.io/network-status"' | jq -j -r '[foreach .[] as $item ([[],[]];0; if ($item.name == "'"$netname"'") then $item.ips[0] else null end)] |map(select(. != null)) | if(length > 0) then .[0] else "" end'
	    local -i i
	    for i in "${PIPESTATUS[@]}" ; do
		if (( i > 0 )) ; then
		    return "$i"
		fi
	    done
	else
	    oc get pod -ojson "$@" | jq -r '.status.podIP | select(.!=null)'
	fi
	return 0
    else
	return 1
    fi
}

if (( ! print_only )) ; then
    if (( initialize_ns )) && oc get ns "$namespace" >/dev/null 2>&1 ; then
	oc delete ns "$namespace" 1>&2
    fi

    if ! oc get project "$namespace" >/dev/null 2>&1 ; then
	oc adm new-project "$namespace" 1>&2
	oc project "$namespace" 1>&2
    elif [[ $(oc project -q) != "$namespace" ]] ; then
	oc project "$namespace" 1>&2
    fi

    if ! oc get serviceaccount "$namespace" >/dev/null 2>&1; then
	oc create serviceaccount "$namespace" 1>&2
	oc adm policy add-cluster-role-to-user cluster-admin "$namespace" 1>&2
	oc adm policy add-scc-to-user privileged -z "$namespace" 1>&2
    fi

    oc delete deployment --all 1>&2
    oc delete pods --all 1>&2

    oc get secret "$secret_name" >/dev/null 2>&1 && oc delete secret "$secret_name" 1>&2
    oc delete service --all 1>&2

    dnsserver=$(oc get service -n openshift-dns dns-default -ojson | jq -r '.spec.clusterIP')
else
    dnsserver=8.8.8.8
fi

function create_extra_credential_benchmark() {
    local tmpdir="$1"
    shift
    if [[ -n "${BENCH_ARMY_KNIFE_OVERRIDE_FIO:-}" ]] ; then
	cat 1>&2 <<'EOM'
***** WARNING ******
***** TEMPORARILY using an override of bench-army-knife-fio
***** This should be REMOVED when pbench-fio correctly handles multiple
***** servers with the same IP address!
***** WARNING ******
EOM

	cat > "$tmpdir/20-install-custom-pbench-fio" <<'EOF'
#!/bin/sh
if [[ ${BENCH_ARMY_KNIFE_ROLE:-} = controller ]] ; then
    cat > /opt/pbench-agent/bench-scripts/pbench-fio << 'EOG'
#!/bin/bash
# -*- mode: shell-script; indent-tabs-mode: t; sh-basic-offset: 8; sh-indentation: 8; sh-indent-for-case-alt: + -*-

# This is a script to run the fio benchmark

script_path=`dirname $0`
script_name=`basename $0`
pbench_bin="`cd ${script_path}/..; /bin/pwd`"

# source the base script
. "$pbench_bin"/base

benchmark="fio"
benchmark_rpm=${benchmark}
export benchmark_run_dir=""
# allow unit tests to override
if [[ -z "$benchmark_bin" ]]; then
	benchmark_bin=/usr/local/bin/$benchmark
fi
ver="$(getconf.py version fio)"
if [[ -z "${ver}" ]]; then
	error_log "pbench-fio: package version is missing in config file"
	exit 1
fi
fio_server_port="$(getconf.py server_port fio)"
if [[ -z "${fio_server_port}" ]]; then
	error_log "pbench-fio: server_port is missing in config file"
	exit 1
fi

job_file="${script_path}/templates/fio.job"

# Every bench-script follows a similar sequence:
# 1) process bench script arguments
# 2) ensure the right version of the benchmark is installed
# 3) gather pre-run state
# 4) run the benchmark and start/stop perf analysis tools
# 5) postprocess analysis tool data
# 6) gather post-run state
# 7) postprocess benchmark data

orig_cmd="$*"

# Defaults
run_dir=""
keep_failed_tool_data="y"
tar_nonref_data="y"
postprocess_only="n"
nr_samples=5
maxstddevpct=5 # maximum allowable standard deviation in percent
max_failures=6 # after N failed attempts to hit below $maxstddevpct, move on to the nest test
supported_test_types="read,write,rw,randread,randwrite,randrw"
test_types="read,randread"		# default is -non- destructive
install_only="n"
config=""
rate_iops=""
block_sizes="4,64,1024"
targets="/tmp/fio"
numjobs=""
runtime=""
ramptime=""
iodepth=""
ioengine=""
pre_iteration_script=""
job_mode_def="concurrent"
job_mode=${job_mode_def} # serial or concurrent targets
file_size=""
direct="" # don't cache IO's by default
sync="" # don't sync IO's by default
clients=""
client_file=""
tool_label_pattern="fio-"
tool_group="default"
max_key_length=20
primary_metric="readwrite_IOPS"
histogram_interval_sec=$(getconf.py histogram-interval-sec pbench-fio)
if [ -z "$histogram_interval_sec" ] ;then
	histogram_interval_sec=10
fi
sysinfo="default"
declare -a client_names=()
declare -A client_ports=()
unique_ports=0

function usage {
	printf "The following options are available:\n"
	printf "\n"
	printf -- "\t-t str[,str] --test-types=str[,str]\n"
	printf "\t\tone or more of %s\n" $supported_test_types
	printf "\n"
	printf -- "\t--direct=[0/1]\n"
	printf "\t\t1 = O_DIRECT enabled (default), 0 = O_DIRECT disabled\n"
	printf "\n"
	printf -- "\t--sync=[0/1]\n"
	printf "\t\t1 = O_SYNC enabled, 0 = O_SYNC disabled (default)\n"
	printf "\n"
	printf -- "\t--rate-iops=int\n"
	printf "\t\tdo not exceeed this IOP rate (per job, per client)\n"
	printf "\n"
	printf -- "\t-r int --runtime=int\n"
	printf "\t\truntime in seconds (default is $runtime)\n"
	printf "\n"
	printf -- "\t--ramptime=int\n"
	printf "\t\ttime in seconds to warm up test before taking measurements (default is $ramptime)\n"
	printf "\n"
	printf -- "\t-b int[,int] --block-sizes=str[,str] (default is $block_sizes)\n"
	printf "\t\tone or more block sizes in KiB\n"
	printf "\n"
	printf -- "\t-s int[,int] --file-size=str[,str] (no default)\n"
	printf "\t\tfile sizes in MiB\n"
	printf "\n"
	printf -- "\t-d str[,str] --targets=str[,str]\n"
	printf "\t\tone or more directories or block devices (default is $targets)\n"
	printf "\t\t(persistent names for devices highly recommended)\n"
	printf "\n"
	printf -- "\t-j str --job-mode=str    str=[serial|concurrent]  (default is '${job_mode_def}')\n"
	printf "\t\tdirects how --targets parameter(s) is/are used; with 'serial' mode all combinations\n"
	printf "\t\tof fio job parameters are run against each target one at a time, while with 'concurrent'\n"
	printf "\t\tmode all target devices are used at the same time.\n"
	printf "\n"
	printf -- "\t--ioengine=str           str= any ioengine fio supports (default is $ioengine)\n"
	printf "\n"
	printf -- "\t--iodepth=<int>"
	printf "\t\tSet the iodepth config variable in the fio job file\n"
	printf "\n"
	printf -- "\t-c str[,str] --clients=str[,str]      str= a list of one or more host names (hosta,hostb,hostc) where you want fio to run\n"
	printf "\t\tIf no clients are specified, fio is run locally\n"
	printf "\t\tNote: the pbench-agent must be installed on each of the client systems already.\n"
	printf "\n"
	printf -- "\t--client-file=str        str= file (with absolute path) which contains 1 client per line\n"
	printf "\n"
	printf -- "\t--config=str\n"
	printf "\t\tname of the test configuration\n"
	printf "\n"
	printf -- "\t--tool-group=str\n"
	printf "\n"
	printf -- "\t--postprocess-only=[y|n]\n"
	printf "\t\tuse this only if you want to postprocess an existing result again\n"
	printf "\t\tyou must use --run-dir option with this\n"
	printf "\n"
	printf -- "\t--run-dir=<path>\n"
	printf "\t\tprovide the path of an existig result (typically somewhere in $pbench_run\n"
	printf "\n"
	printf -- "\t--numjobs=<int>\n"
	printf "\t\tnumber of jobs to run, if not given then fio default of numjobs=1 will be used\n"
	printf "\n"
	printf -- "\t--job-file=<path>\n"
	printf "\t\tprovide the path of a fio job config file, (default is $job_file)\n"
	printf "\n"
	printf -- "\t--pre-iteration-script=str\n"
	printf "\t\tuse executable script/program to prepare the system for test iteration\n"
	printf "\t\texample: --pre-iteration-script=\$HOME/drop-cache.sh\n"
	printf "\n"
	printf -- "\t--samples=<int>\n"
	printf "\t\tnumber of samples to use per test iteration (default is $nr_samples)\n"
	printf "\n"
	printf -- "\t--max-stddev=<int>\n"
	printf "\t\tthe maximum percent stddev allowed to pass\n"
	printf "\n"
	printf -- "\t--max-failures=<int>\n"
	printf "\t\tthe maximum number of failures to get below stddev\n"
	printf "\n"
	printf -- "\t--install\n"
	printf "\t\tinstall only (default is False)\n"
	printf "\n"
	printf -- "\t--histogram-interval-sec=<int>\n"
	printf "\t\tset the histogram logging interval in seconds (default $histogram_interval_sec)\n"
	printf "\n"
	printf -- "\t--sysinfo=str            str= comma separated values of sysinfo to be collected\n"
	printf "\t\tavailable: $(pbench-collect-sysinfo --options)\n"
	printf "\n"
	printf -- "\t--unique-ports           Use unique ports for each server\n"
}

function fio_process_options() {
	opts=$(getopt -q -o b:c:d:hj:r:s:t: --longoptions "help,max-stddev:,max-failures:,samples:,direct:,sync:,install,remote-only,clients:,client-file:,iodepth:,ioengine:,config:,jobs-per-dev:,job-mode:,rate-iops:,ramptime:,runtime:,test-types:,block-sizes:,file-size:,targets:,tool-group:,postprocess-only:,run-dir:,numjobs:,job-file:,sysinfo:,pre-iteration-script:,histogram-interval-sec:,histogram-interval-msec:,unique-ports" -n "getopt.sh" -- "$@");
	if [ $? -ne 0 ]; then
		printf -- "${script_name} $*\n"
		printf -- "\n"
		printf -- "\tunrecognized option specified\n\n"
		usage
		exit 1
	fi
	eval set -- "$opts";
	while true; do
		case "$1" in
		-h|--help)
			usage
			exit
			;;
		--install)
			shift;
			if [[ "$postprocess_only" != "n" ]]; then
				printf -- "${script_name} $*\n"
				printf -- "\n"
				printf -- "\t--install not compatible with specified \"--postprocess-only ${postprocess_only}\" option\n\n"
				usage
				exit 1
			fi
			install_only="y"
			;;
		--remote-only)
			shift;
			warn_log "--remote-only is deprecated, ignoring (was non-operational previously)"
			;;
		--max-stddev)
			shift;
			if [ -n "$1" ]; then
				maxstddevpct="$1"
				shift;
			fi
			;;
		--max-failures)
			shift;
			if [ -n "$1" ]; then
				max_failures="$1"
				shift;
			fi
			;;
		--samples)
			shift;
			if [ -n "$1" ]; then
				nr_samples="$1"
				shift;
			fi
			;;
		--direct)
			shift;
			if [ -n "$1" ]; then
				direct=$1
				shift;
			fi
			;;
		--sync)
			shift;
			if [ -n "$1" ]; then
				sync=$1
				shift;
			fi
			;;
		-t|--test-types)
			shift;
			if [ -n "$1" ]; then
				test_types="$1"
				shift;
			fi
			;;
		-b|--block-sizes)
			shift;
			if [ -n "$1" ]; then
				block_sizes="$1"
				shift;
			fi
			;;
		-s|--file-size)
			shift;
			if [ -n "$1" ]; then
				file_size="$1"
				shift;
			fi
			;;
		--ramptime)
			shift;
			if [ -n "$1" ]; then
				ramptime="$1"
				shift;
			fi
			;;
		--rate-iops)
			shift;
			if [ -n "$1" ]; then
				rate_iops="$1"
				shift;
			fi
			;;
		-r|--runtime)
			shift;
			if [ -n "$1" ]; then
				runtime="$1"
				shift;
			fi
			;;
		-c|--clients)
			shift;
			if [ ! -z "$client_file" ] ;then
				printf -- "${script_name} $*\n"
				printf -- "\n"
				printf -- "\t-c|--clients and --client-file are mutually exclusive\n\n"
				usage
				exit 1
			fi
			if [ -n "$1" ]; then
				clients="$1"
				shift;
			fi
			;;
		--client-file)
			shift;
			if [ ! -z "$clients" ] ;then
				printf -- "${script_name} $*\n"
				printf -- "\n"
				printf -- "\t--client-file and -c|--clients are mutually exclusive\n\n"
				usage
				exit 1
			fi
			client_file=$1
			shift;
			if [ ! -e "${client_file}" ]; then
				printf -- "${script_name} $*\n"
				printf -- "\n"
				printf -- "\tSpecified client file, ${client_file}, does not exist\n\n"
				usage
				exit 1
			fi
			if [[ "$client_file" != /* ]] ;then
				# make it absolute
				client_file=$PWD/$client_file
			fi
			while read line; do
				clients="$clients,$line"
			done < ${client_file}
			# Remove the leading comma since $clients starts off empty
			clients=`echo $clients | sed -e 's/^,//'`
			;;
		-d|--targets)
			shift;
			if [ -n "$1" ]; then
				targets="$1"
				shift;
			fi
			;;
		-j|--job-mode)
			shift;
			if [ -n "$1" ]; then
				job_mode="$1"
				shift;
			fi
			;;
		--config)
			shift;
			if [ -n "$1" ]; then
				config="$1"
				shift;
			fi
			;;
		--ioengine)
			shift;
			if [ -n "$1" ]; then
				ioengine="$1"
				shift;
			fi
			;;
		--iodepth)
			shift;
			if [ -n "$1" ]; then
				iodepth="$1"
				shift;
			fi
			;;
		--tool-group)
			shift;
			if [ -n "$1" ]; then
				tool_group="$1"
				shift;
			fi
			;;
		--postprocess-only)
			shift;
			if [ -n "$1" ]; then
				postprocess_only="$1"
				shift;
				if [[ "$postprocess_only" != "n" && "$install_only" == "y" ]]; then
					printf -- "${script_name} $*\n"
					printf -- "\n"
					printf -- "\t\"--postprocess-only ${postprocess_only}\" not compatible with specified --install option\n\n"
					usage
					exit 1
				fi
			fi
			;;
		--run-dir)
			shift;
			if [ -n "$1" ]; then
				run_dir="$1"
				shift;
			fi
			;;
		--numjobs)
			shift;
			if [ -n "$1" ]; then
				numjobs="$1"
				shift;
			fi
			;;
		--job-file)
			shift;
			if [ -n "$1" ]; then
				job_file="$1"
				shift;

			fi
			;;
		--pre-iteration-script)
			shift;
			if [ -n "$1" ]; then
				pre_iteration_script="$1"
				if [ ! -x $pre_iteration_script ]; then
					printf "ERROR: $pre_iteration_script must be executable\n"
					exit 1
				fi
				shift;
			fi
			;;
		--histogram-interval-sec)
			shift;
			histogram_interval_sec="$1"
			shift
			;;
			# histogram-interval-msec is only kept for backwards compatibility
			# it is deprecated and is not documented in the --help output
		--histogram-interval-msec)
			shift;
			(( histogram_interval_sec = $1 / 1000 ))
			shift
			;;
		--sysinfo)
			shift;
			if [ -n "$1" ]; then
				sysinfo="$1"
				shift;
			fi
			;;
		--unique-ports)
			shift;
			unique_ports=1
			;;
		--)
			shift;
			break;
			;;
		*)
			echo "what's this? [$1]"
			shift;
			break;
			;;
		esac
	done
	verify_common_bench_script_options $tool_group $sysinfo

	if [[ ${job_mode} != "serial" && ${job_mode} != "concurrent" ]]; then
		error_log "Unsupported --job-mode=${job_mode} encountered"
		usage
		exit 1
	fi

	local tt=""
	space_sep_vtt=$(echo $supported_test_types | sed -e s/,/" "/g)
	for tt in $(echo "$test_types" | sed -e s/,/" "/g); do
		local found=0
		for vtt in ${space_sep_vtt}; do
			if [[ "${tt}" == "${vtt}" ]]; then
				found=1
				break;
			fi
		done
		if [[ ${found} -ne 1 ]]; then
			error_log "Unsupported --test-types=${test_types} encountered"
			usage
			exit 1
		fi
	done

	if [ "$postprocess_only" = "n" ]; then
		benchmark_fullname="${benchmark}_${config}_${date_suffix}"
		benchmark_run_dir="$pbench_run/${benchmark_fullname}"
	else
		if [ -z "$run_dir" ]; then
			error_log "Please specify a directory if postprocessing an existing result (--run-dir=)"
			exit 1
		fi
		benchmark_fullname="$(basename $run_dir)"
		benchmark_run_dir="$run_dir"
	fi
	if [[ -n "$clients" ]] ; then
		for client in ${clients//,/ } ; do
			if [[ $client = *':'* ]] ; then
				client_name=${client%%:*}
				client_port=${client#*:}
			else
				client_name=$client
				client_port=$fio_server_port
				if (( unique_ports )) ; then
					fio_server_port=$((fio_server_port+1))
				fi
			fi
			client_names+=("$client_name")
			client_ports["$client_name"]=$client_port
		done
	fi
}

function record_iteration {
	local count=${1}
	local test_type=${2}
	local block_size=${3}
	local dev=${4}
	local iteration=${5}

	local mdlog=${benchmark_run_dir}/metadata.log
	echo ${iteration} >> ${benchmark_iterations}
	echo ${count} | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_number
	echo ${test_type} | pbench-add-metalog-option ${mdlog} iterations/${iteration} test_type
	echo ${block_size} | pbench-add-metalog-option ${mdlog} iterations/${iteration} block_size_KiB
	echo ${dev} | pbench-add-metalog-option ${mdlog} iterations/${iteration} dev
	echo ${iteration} | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_name
}

# Ensure the right version of the benchmark is installed
function fio_install() {
	if check_install_rpm ${benchmark_rpm} ${ver}; then
		debug_log "[${script_name}] ${benchmark_rpm}-${ver} is installed"
	else
		debug_log "[${script_name}] ${benchmark_rpm}-${ver} is not installed, exiting"
		exit 1
	fi
	if [ ! -z "$clients" ] ; then
		debug_log "verifying clients have fio installed"
		echo "verifying clients have fio installed"
		for client in "${client_names[@]}" ; do
			ssh $ssh_opts $client ${pbench_install_dir}/bench-scripts/$script_name --install &
		done
		# FIXME - save the pid and wait for each pid to ensure it returns with success
		wait
	fi
}

# Make sure this devices exists
function fio_device_check() {
	local devs=$1
	local clients=$2
	local dev=""
	local client=""
	local rc=0

	debug_log "fio_device_check(devs=\"${devs}\", clients=\"${clients}\")"
	for dev in `echo $devs | sed -e s/,/" "/g`; do
		if echo $dev | grep -q "^/dev/"; then
			if [ ! -z "$clients" ]; then
				for client in "${client_names[@]}" ; do
					debug_log "checking to see if $dev exists on client $client"
					ssh $ssh_opts $client "if [ -L $dev ]; then dev=`dirname $dev`/`readlink $dev`; fi; test -b $dev" || rc=1
				done
			else
				if [ -L $dev ]; then dev=`dirname $dev`/`readlink $dev`; fi; test -b $dev || rc=1
			fi
			if [ $rc -eq 1 ]; then
				error_log "At least one client did not have block device $dev, exiting"
				exit 1
			fi
		fi
	done
}

function fio_create_jobfile() {
	local fio_job_file="${13}"
	local fio_job_file_path=$(dirname "${fio_job_file}")
	mkdir -p "${fio_job_file_path}"
	if [ ${?} -ne 0 ]; then
		error_log "Failed to create path to job file \"${fio_job_file}\""
		exit 1
	fi
	"${script_path}/templates/make-fio-jobfile.py" -j ${job_file} \
		-rw="${1}" \
		-ioengine="${2}" \
		-bs="$(printf %sk ${3})" \
		-iodepth="${4}" \
		-direct="${5}" \
		-sync="${6}" \
		-runtime="${7}" \
		-ramptime="${8}" \
		-size="${9}" \
		-rate_iops="${10}" \
		-log_hist_msec="${11}" \
		-targets $(echo "${12}" | sed -e 's/,/ /g') \
		-numjobs="${14}" \
		| sed -e 's/ = /=/g' > ${fio_job_file}

	if [ ${?} -ne 0 ]; then
		error_log "Failed to create job file \"${fio_job_file}\""
		exit 1
	fi
	echo "Created the following job file (${fio_job_file}):"
	cat ${fio_job_file}
}

function does_wildcard_exist() {
	local fn_pat=$1
	local found=1
	for fn in ${fn_pat}; do
		if [[ -e ${fn} ]]; then
			found=0
			break
		fi
	done
	return ${found}
}

function fio_run_job() {
	local iteration="$1"
	local benchmark_results_dir="$2"
	local fio_job_file="$3"
	local bench_opts="--output-format=json $fio_job_file"
	local tgts="$4"
	local clients="$5"

	mkdir -p $benchmark_results_dir/clients
	if [[ ! -d $benchmark_results_dir/clients ]]; then
		error_log "Failed to create results directory hierarchy: $benchmark_results_dir/clients"
		exit 1
	fi

	echo "running fio job: $fio_job_file ($(basename $benchmark_results_dir))"

	if [ ! -z "$clients" ]; then
		debug_log "creating directories on the clients"
		for client in "${client_names[@]}"; do
			ssh $ssh_opts $client mkdir -p $benchmark_results_dir &
		done
		wait
		debug_log "opening port 8765 on firewall on the clients"
		for client in "${client_names[@]}"; do
			ssh $ssh_opts $client "firewall-cmd --add-port=${client_ports[$client]}/tcp >/dev/null" &
		done
		wait
		debug_log "killing any old fio process on the clients"
		for client in "${client_names[@]}"; do
			ssh $ssh_opts $client "killall fio >/dev/null 2>&1" &
		done
		wait
		debug_log "starting new fio process on the clients"
		for client in "${client_names[@]}"; do
			ssh $ssh_opts $client "pushd $benchmark_results_dir >/dev/null; screen -dmS fio-server bash -c ''$benchmark_bin' --server=,${client_ports[$client]} 2>&1 |tee -a /var/tmp/all-client-results >client-result.txt'"
		done
		wait
		debug_log "waiting for fio process(server) to start on clients"
		for client in "${client_names[@]}"; do
			timeout --kill-after=1 60 bash -c 'until printf "" 2>>/dev/null >>/dev/tcp/$0/$1; do sleep 1; done' $client ${client_ports[$client]}
			if [[ $? -eq 124 ]]; then
				error_log "fio process took more than 60 seconds to start in client $client, failing"
				exit 1
			fi
		done
	else
		mkdir -p $benchmark_results_dir/clients/localhost
	fi

	local client_opts=""

	if [ ! -z "$clients" ]; then
		# If a client-file parameter was passed, then clients is
		# already initialized to its contents.
		local max_jobs=0
		local nclients=0

		if [ ! -z $numjobs ]; then
			# so that a separate filename will be generated
			# for each (host, job-number) pair
			let max_jobs=$numjobs
		else
			for t in `echo $tgts | sed -e s/,/" "/g` ; do
				let max_jobs=$max_jobs+1
			done
		fi

		let nclients=`wc -l < $_client_file`
		let max_jobs=$max_jobs*$nclients
		client_opts="$client_opts --client=$_client_file --max-jobs=$max_jobs"
	fi

	# Certain test preparation steps such as cache dropping can be a bit
	# hard on the system, give it a few seconds before actually starting
	# test by putting this before pbench-start-tools.
	if [ -n "$pre_iteration_script" ] ; then
		printf "running pre-iteration-script command: $pre_iteration_script\n"
		eval "$pre_iteration_script"
	fi
	pbench-start-tools --group=$tool_group --dir=$benchmark_results_dir

	# create a command file and keep it with the results for debugging later, or user can run outside of pbench
	echo "$benchmark_bin $client_opts $bench_opts" >$benchmark_results_dir/fio.cmd
	chmod +x $benchmark_results_dir/fio.cmd
	debug_log "$benchmark: Going to run [$benchmark_bin $bench_opts $client_opts]"
	pushd $benchmark_results_dir >/dev/null
	$benchmark_results_dir/fio.cmd >$benchmark_results_dir/fio-result.txt
	popd >/dev/null

	pbench-stop-tools --group=$tool_group --dir=$benchmark_results_dir
	pbench-postprocess-tools --group=$tool_group --dir=$benchmark_results_dir

	if [ ! -z "$clients" ]; then
		histogram_params="--time-quantum ${histogram_interval_sec} --percentiles 0 50 90 95 99 100"
		histogram_cmd="fio-histo-log-pctiles.py ${histogram_params} -- "
		for client in "${client_names[@]}"; do
			mkdir -p $benchmark_results_dir/clients/$client
			/bin/mv $benchmark_results_dir/*.log.$client $benchmark_results_dir/clients/$client/ 2> /dev/null
			# remove the trailing client name in the log file names
			pushd $benchmark_results_dir/clients/$client >/dev/null
			for i in `/bin/ls | grep log`; do
				mv $i `echo $i | sed -e s/\.$client//`
			done
			popd >/dev/null
			# Process the histograms
			# Determine histogram interval based on value used in job file.
			#my $log_interval = `cat $dir/fio.job | grep "^log_hist_msec"`;
			#if [ ! $log_interval =~ /^\s*$/ ]; then
			if grep -q "^log_hist_msec" $fio_job_file; then
				does_wildcard_exist $benchmark_results_dir/clients/$client/'fio_clat_hist.*.log*'
				if [[ $? -eq 0 ]]; then
					mkdir -p $benchmark_results_dir/clients/$client/hist
					# compute per-client latency percentiles
					$histogram_cmd $benchmark_results_dir/clients/$client/fio_clat_hist.*.log* >$benchmark_results_dir/clients/$client/hist/hist.csv
					$script_path/postprocess/$benchmark-postprocess-viz.py --job-file=$fio_job_file ${histogram_params} -- $benchmark_results_dir/clients/$client/hist
				else
					warn_log "log_hist_msec specified in job file but failed to find any log files (.../clients/$client/fio_clat_hist.*.log*) to process for histograms"
				fi
			fi
		done
		# compute cluster-wide latency percentiles
		if grep -q "^log_hist_msec" $fio_job_file; then
			does_wildcard_exist $benchmark_results_dir/clients/'*/fio_clat_hist.*.log*'
			if [[ $? -eq 0 ]]; then
				mkdir $benchmark_results_dir/hist
				$histogram_cmd $benchmark_results_dir/clients/*/fio_clat_hist.*.log* >$benchmark_results_dir/hist/hist.csv
				$script_path/postprocess/$benchmark-postprocess-viz.py --job-file=$fio_job_file ${histogram_params} -- $benchmark_results_dir/hist
			else
				warn_log "log_hist_msec specified in job file but failed to find any log files (.../clients/*/fio_clat_hist.*.log*) to process for histograms"
			fi
		fi
	else
		/bin/mv $benchmark_results_dir/*.log $benchmark_results_dir/clients/localhost/ 2> /dev/null
	fi

	echo "fio job complete"
}

# Run the benchmark and start/stop perf analysis tools
function fio_run_benchmark() {
	(( histogram_interval_msec = histogram_interval_sec * 1000 ))

	if [[ ! -z "$client_file" ]] ;then
		# Copy the clients file given on the command line into the run
		# directory to keep it with the run.
		cp $client_file $benchmark_run_dir/fio-client.file
		_client_file=$benchmark_run_dir/fio-client.file
	else
		if [[ ! -z "$clients" ]]; then
			# Record the -c|--clients list into the
			# fio-client.file.  This makes the fio command shorter
			# by always using a client file regardless of how
			# clients were specified.  We only need to save the
			# client list once in the benchmark run directory.
			_client_file=$benchmark_run_dir/fio-client.file
			for client in "${client_names[@]}"; do
				echo ip:$client,${client_ports[$client]}
			done > $_client_file
		fi
	fi

	local count=1
	if [ "$job_mode" = "serial" ]; then
		# if each target is separated by a space, there will be one job for each in next for loop
		targets=`echo $targets | sed -e s/,/" "/g`
	fi
	typeset -i ntargets=$(echo $targets | wc -w)
	typeset -i ntesttypes=$(echo $test_types | sed -e 's/,/ /g' | wc -w)
	typeset -i nblocksizes=$(echo $block_sizes | sed -e 's/,/ /g' | wc -w)
	typeset -i total_iterations=$ntargets*$ntesttypes*$nblocksizes
	for dev in $targets; do
		for test_type in `echo $test_types | sed -e s/,/" "/g`; do
			for block_size in `echo $block_sizes | sed -e s/,/" "/g`; do
				job_num=1
				iteration="${count}-${test_type}-${block_size}KiB"
				if [ "$job_mode" = "serial" ]; then
					dev_short_name="`basename $dev`"
					# easier to identify what job used what device when having 1 job per device
					iteration="$iteration-${dev_short_name}"
				fi
				record_iteration ${count} ${test_type} ${block_size} ${dev} ${iteration}
				iteration_dir=$benchmark_run_dir/$iteration
				result_stddevpct=$maxstddevpct # this test case will get a "do-over" if the stddev is not low enough
				failures=0
				while [[ $(echo "if (${result_stddevpct} >= ${maxstddevpct}) 1 else 0" | bc) -eq 1 ]]; do
					if [[ $failures -gt 0 ]]; then
						echo "Restarting iteration $iteration ($count of $total_iterations)"
						log "Restarting iteration $iteration ($count of $total_iterations)"
					fi
					if [ "$postprocess_only" = "n" ]; then
						mkdir -p $iteration_dir
					else
						if [ ! -e $iteration_dir ]; then
							# if the iteration dir does not exist, look for a failed result directory or archive
							fail_nr=$failures
							((fail_nr++))
							fail_tag="-fail$fail_nr"
							failed_iteration_dir="$iteration_dir$fail_tag"
							if [ -e $failed_iteration_dir ]; then
								mv $failed_iteration_dir $iteration_dir || exit 1
							else
								failed_iteration_archive="$iteration_dir$fail_tag.tar.xz"
								if [ -e $failed_iteration_archive ]; then
									echo "using $failed_iteration_archive as $iteration_dir"
									tar -C $benchmark_run_dir -J -x -f $failed_iteration_archive || exit 1
									mv $failed_iteration_dir $iteration_dir || exit 1
								else
									echo "Could not find $iteration_dir, $failed_iteration_dir, or $failed_iteration_archive"
								fi
							fi
						fi
					fi
					if [ -e $iteration_dir ]; then
						fio_job_file="$iteration_dir/fio.job"
						#	      ARG   1		 2	     3		   4	      5		6	7	   8	       9	    10		 11			    12	   13		   14
						fio_create_jobfile "$test_type" "$ioengine" "$block_size" "$iodepth" "$direct" "$sync" "$runtime" "$ramptime" "$file_size" "$rate_iops" "$histogram_interval_msec" "$dev" "$fio_job_file" "$numjobs"
						iteration_failed=0
						sample_failed=0
						for sample in `seq 1 $nr_samples`; do
							# each attempt at a test config requires multiple samples to get stddev
							benchmark_results_dir="$iteration_dir/sample$sample"
							if [ "$postprocess_only" = "n" ]; then
								if [ -e $benchmark_results_dir ]; then
									# FIXME - Shouldn't we error and exit out instead of removing data?
									/bin/rm -rf $benchmark_results_dir
								fi
								mkdir -p $benchmark_results_dir
								fio_run_job "$iteration" "$benchmark_results_dir" "$fio_job_file" "$dev" "$clients"
							else
								# if we are only postprocessing, then we might have to untar an existing result
								pushd $iteration_dir >/dev/null
								if [ ! -e sample$sample ]; then
									if [ -e sample$sample.tar.xz ]; then
										tar Jxf sample$sample.tar.xz && /bin/rm sample$sample.tar.xz
									else
										echo "sample $sample missing.  There should be $nr_samples samples"
									fi
								fi
								popd >/dev/null
							fi
							debug_log "post-processing fio result"
							echo "$script_path/postprocess/$benchmark-postprocess \"$benchmark_results_dir\" \"$tool_label_pattern\" \"$tool_group\"" >"$benchmark_results_dir/$benchmark-postprocess.cmd"
							chmod +x "$benchmark_results_dir/$benchmark-postprocess.cmd"
							$benchmark_results_dir/$benchmark-postprocess.cmd
							rc=$?
							# if for any reason the benchmark postprocessing script fails, consider this a failure to get a sample
							if [ $rc -ne 0 ]; then
								debug_log "failed: $script_path/postprocess/$benchmark-postprocess $benchmark_results_dir $iteration $tool_group"
								sample_failed=1
							fi
							if [ $sample_failed -eq 1 ]; then
								# we need all samples to be good, so bust out of testing samples now
								break
							fi
						done
					fi
					echo "$script_path/postprocess/process-iteration-samples \"$iteration_dir\" \"$primary_metric\" \"$maxstddevpct\" \"$failures\" \"$max_failures\" \"$tar_nonref_data\" \"$keep_failed_tool_data\"" >"$iteration_dir/process-iteration-samples.cmd"
					chmod +x "$iteration_dir/process-iteration-samples.cmd"
					$iteration_dir/process-iteration-samples.cmd
					fail=$?
					if [ $fail -ne	0 ]; then
						((failures++))
					fi
					if [ $fail -eq 0 -o $failures -ge $max_failures ]; then
						break
					fi
				done
			let count=$count+1 # now we can move to the next iteration
			done
		done
	done
}

fio_process_options "$@"
if [ "$postprocess_only" = "n" ]; then
	fio_install
	if [ "$install_only" = "y" ]; then
		exit 0
	fi
	fio_device_check "$targets" "$clients"
	mkdir -p $benchmark_run_dir/.running
	if [[ $? -ne 0 ]]; then
		error_log "Unable to create $benchmark_run_dir path and/or .running marker directory"
		exit 1
	fi
fi

benchmark_iterations="${benchmark_run_dir}/.iterations"
> ${benchmark_iterations}

export benchmark config
pbench-collect-sysinfo --group=$tool_group --dir=$benchmark_run_dir --sysinfo=$sysinfo beg
pbench-metadata-log --group=$tool_group --dir=$benchmark_run_dir beg
# on abnormal exit, make sure that the metadata log exists and is complete.
trap "pbench-metadata-log --group=$tool_group --dir=$benchmark_run_dir int" INT QUIT

fio_run_benchmark
echo "$script_path/postprocess/generate-benchmark-summary \"$benchmark\" \"$orig_cmd\" \"$benchmark_run_dir\"" >"$benchmark_run_dir/generate-benchmark-summary.cmd"
chmod +x "$benchmark_run_dir/generate-benchmark-summary.cmd"
$benchmark_run_dir/generate-benchmark-summary.cmd
pbench-metadata-log --group=$tool_group --dir=$benchmark_run_dir end
pbench-collect-sysinfo --group=$tool_group --dir=$benchmark_run_dir  --sysinfo=$sysinfo end

rmdir $benchmark_run_dir/.running
EOG
fi

EOF
	echo "$tmpdir/20-install-custom-pbench-fio"
    fi
}

function create_credentials_1() {
    local tmpkeydir=
    tmpkeydir=$(umask 77; mktemp -d -t "pbench-agent-key.XXXXXX")
    if [[ -z "${pbench_agent_key:-}" && $print_only -eq 0 ]] ; then
	if [[ -n "${tmpkeydir:-}" ]] ; then
	    # shellcheck disable=SC2064
	    trap "rm -rf $tmpkeydir" INT TERM EXIT
	    ssh-keygen -f "$tmpkeydir/id_rsa" -C "generated pbench agent key" -N '' -q -t rsa
	    pbench_agent_key="$tmpkeydir/id_rsa"
	fi
    fi
    if type -t create_extra_credential_benchmark >/dev/null ; then
	local entry
	while read -r entry ; do
	    additional_files+=("$entry");
	done < <(create_extra_credential_benchmark "$tmpkeydir" "${additional_files[@]}")
    fi

    additional_files+=("id_rsa=$pbench_private_key")
    additional_files+=("pbench-agent.cfg=$pbench_agent_cfg")
    additional_files+=("id_rsa_agent=$pbench_agent_key")
    additional_files+=("id_rsa_agent.pub=${pbench_agent_key}.pub")
    _oc create secret generic "$secret_name" "${additional_files[@]/#/--from-file=}"
    if [[ -n "${tmpkeydir:-}" && -d "$tmpkeydir" ]] ; then
	rm -rf "$tmpkeydir"
    fi
}

function create_credentials() {
    (create_credentials_1)
}

function indent_1() {
    local -i column="$1"
    local line=
    while IFS='' read -r 'line' ; do
	if [[ -n "${line:-}" ]] ; then
	    local prefix=
	    if [[ $line = '#'* ]] ; then
		line=${line:1}
		prefix='#'
	    fi
	    printf "%s%${column}s%s\n" "$prefix" ' ' "$line"
	fi
    done
}

function indent() {
    local -i column="$1"
    shift
    if [[ -n "$*" ]] ; then
	# "$@" | indent_1 "$column" strips leading whitespace with bash 4.2
	indent_1 "$column" < <("$@")
    else
	indent_1 "$column"
    fi
}

function clean() {
    expand |grep -v '^ *$'
}

function generate_ports() {
    local basename=$1
    local -i baseport=$2
    local -i nports=$3
    shift 3
    local -a protocols=("$@")
    if (( ! ${#protocols[@]})) ; then
	protocols=(TCP UDP)
    fi
    local -i i
    local prot
    for i in $(seq "$baseport" $((baseport + nports - 1)) ) ; do
	for prot in "${protocols[@]}" ; do
	    [[ $prot = TCP ]] && prot=
	    local prot1=${prot:0:1}
	    clean <<EOF
  - name: ${basename}${prot1,,}$i
    port: $i
    ${prot:+protocol: $prot}
EOF
	done
    done
}

# Until privileged containers work with Kata
function security_context() {
    if (( force_privileged == 0 &&
	      ((kata && force_external_agents != 0) ||
		   (force_external_agents == 1)) )) ; then
	clean <<'EOF'
capabilities:
  add:
  - AUDIT_WRITE
  - IPC_LOCK
  - NET_ADMIN
  - NET_RAW
  - SYS_ADMIN
  - SYS_CHROOT
  - SYS_MODULE
EOF
    else
	clean <<'EOF'
privileged: true
EOF
    fi
}

function runtime_class() {
    if (( kata )) ; then
	clean <<'EOF'
runtimeClassName: "kata"
EOF
    fi
}

function host_network() {
    if (( host_networking )) ; then
	clean <<'EOF'
hostNetwork: true
EOF
    fi
}

function create_object() {
    local data
    data="$("$@" | expand)"
    if [[ -n "${data:-}" ]] ; then
	echo "Creating $*" 1>&2
	_oc apply -f - <<< "$data" || {
	    echo "Failing object:" 1>&2
	    echo "$data" 1>&2
	    return 1
	}
    fi
}

function create_resources() {
    if [[ -n "${pod_cpu_request:-}" || -n "${pod_cpu_limit:-}" ||
	      -n "${pod_memory_request:-}" || -n "${pod_memory_limit:-}" ]] ; then
	echo "resources:"
	if [[ -n "${pod_cpu_request:-}" || -n "${pod_memory_request}" ]] ; then
	    clean <<EOF
  requests:
    ${pod_cpu_request:+cpu: "$pod_cpu_request"}
    ${pod_memory_request:+memory: "$pod_memory_request"}
EOF
	fi
	if [[ -n "${pod_cpu_limit:-}" || -n "${pod_memory_limit}" ]] ; then
	    clean <<EOF
  limits:
    ${pod_cpu_limit:+cpu: "$pod_cpu_limit"}
    ${pod_memory_limit:+memory: "$pod_memory_limit"}
EOF
	fi
    fi
}

function create_affinity_terms() {
    local term
    for term in "$@" ; do
	clean <<EOF
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
    matchExpressions:
    - key: ${term%%=*}
      operator: In
      values:
      - "${term#*=}"
  topologyKey: kubernetes.io/hostname
EOF
    done
}

function create_affinities() {
    local -a affinities=()
    local -a antiaffinities=()
    OPTIND=0
    while getopts 'a:A:' opt "$@" ; do
	case "$opt" in
	    a) affinities+=("$OPTARG")     ;;
	    A) antiaffinities+=("$OPTARG") ;;
	    *) ;;
	esac
    done
    if (( ${#affinities[@]} + ${#antiaffinities[@]} )) ; then
	echo "affinity:"
	if (( ${#affinities[@]} )) ; then
	    echo "  podAffinity:"
	    indent 4 create_affinity_terms "${affinities[@]}"
	fi
	if (( ${#antiaffinities[@]} )) ; then
	    echo "  podAntiAffinity:"
	    indent 4 create_affinity_terms "${antiaffinities[@]}"
	fi
    fi
}

function pbench-benchmark-podname-base() {
    local type=$1
    echo "${namespace}${type:+-$type}"
}

function pbench-benchmark-environment() {
    if [[ -n "$*" ]] ; then
	echo "env:"
	local var
	local value
	for var in "$@" ; do
	    value=${var#*=}
	    var=${var%%=*}
	    clean <<EOF
- name: "$var"
  value: "$value"
EOF
	done
    fi
}

function persistent_volume_mount() {
    if [[ -n "${pvname:-}" ]] ; then
	clean <<EOF
- name: "$pvname"
  mountPath: "$pvmount_path"
EOF
    fi
}

function persistent_volume_decl() {
    if [[ -n "${pvname:-}" ]] ; then
	clean <<EOF
- name: "$pvname"
EOF
	if [[ -n "${pvtype_key:-}" ]] ; then
	    clean <<EOF
  $pvtype:
    $pvtype_key: "$pvscoped_name"
EOF
	else
	    clean <<EOF
  $pvtype: {}
EOF
	fi
    fi
}

function persistent_volume_extra_args() {
    local basename=$1
    local count=$2
    if [[ -n "${pvname:-}" ]] ; then
	local -a targets
	readarray -t targets < <(seq -f "$pvmount_path/${basename}-${bm_name}-%.0f${suffix:-}" 1 "$count")
	clean <<EOF
- "--target=$(IFS=,; echo "${targets[*]}")"
#- "--job-file=/opt/pbench-agent/bench-scripts/templates/fio-shared-fs.job"
EOF
    fi
}

function pbench-benchmark-pod() {
    local -a etchosts_addons=()
    local -A extra_hosts=()
    local affinity_string=
    local -a affinities=()
    local -a antiaffinities=()
    local -a environment=()
    local ipaddr
    local host
    local suffix=

    OPTIND=0
    while getopts 'E:H:s:a:A:' opt "$@" ; do
	case "$opt" in
	    a) affinity_string+=" -a $OPTARG" ;;
	    A) affinity_string+=" -A $OPTARG" ;;
	    H) etchosts_addons+=("$OPTARG")   ;;
	    E) environment+=("$OPTARG")	      ;;
	    s) suffix="-${OPTARG}"	      ;;
	    *) ;;
	esac
    done
    shift $((OPTIND-1))

    for datum in "${etchosts_addons[@]}" ; do
	if [[ $datum =~ ^([^=]+)=(.+) ]] ; then
	    ipaddr="${BASH_REMATCH[1]}"
	    host="${BASH_REMATCH[2]}"
	    extra_hosts[$host]+=" $ipaddr"
	fi
    done

    local type=${1:-}
    affinity_string+=" -a app-subtype=${bm_name}${type:+-$type}"
# shellcheck disable=SC2086
    clean <<EOF
---
apiVersion: v1
kind: Pod
metadata:
  name: $(pbench-benchmark-podname-base "$type")${suffix}
  namespace: "$namespace"
  labels:
    bench-army-knife-id: "$job_uuid"
    k8s-app: ${namespace}-${bm_name}${type:+-$type}
    app: ${bm_name}
    app-subtype: ${bm_name}${type:+-$type}
    name: ${namespace}${type:+-$type}
    ${selector_key}: "true"
    bench-army-knife-sync: "12"
  selector:
    matchLabels:
      app: ${namespace}${type:+-$type}
      name: ${namespace}${type:+-$type}
      app-subtype: ${bm_name}${type:+-$type}
      ${selector_key}: "true"
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  serviceAccount: ${namespace}
$(indent 2 runtime_class)
  restartPolicy: Never
$(indent 2 create_affinities $affinity_string)
  containers:
  - name: "${namespace}-agent"
    securityContext:
$(indent 6 security_context)
$(indent 4 create_resources)
    image: "quay.io/rkrawitz/bench-army-knife:latest"
    command:
    - "/usr/local/bin/bootstrap.sh"
    args:
${pre_script:+    - "$secret_root/$pre_script"}
    - "$pbench_agent_container_bin"
    $( ((quiet)) && echo '- "-q"')
$( (( waitforever )) && echo "    - -w")
    - "-L"
    - "-a"
    - "${namespace}${type:+-$type}${suffix}"
    - "-D"
    - "$secret_root/"
    - "-n"
    - "$dnsserver"
    - "-K"
    - "id_rsa_agent"
    - "$port"
    - "${namespace}-controller.$namespace"
$(indent 4 pbench-benchmark-environment "${environment[@]}")
    terminationGracePeriodSeconds: 1
    volumeMounts:
    - name: "$secret_name"
      mountPath: "$secret_root"
      readOnly: true
$(indent 4 persistent_volume_mount)
  volumes:
  - name: "$secret_name"
    secret:
      defaultMode: 0400
      secretName: "$secret_name"
$(indent 2 persistent_volume_decl)
EOF
}

# For the underlying host in the case of Kata pods.
function agent_deployment() {
    if (( (kata && force_external_agents != 0) || (force_external_agents == 1) )) ; then
	clean <<EOF
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${namespace}-agent-host
  namespace: "$namespace"
  labels:
    bench-army-knife-id: "$job_uuid"
    k8s-app: bench-army-knife-agent-deployment
spec:
  replicas: $((1 + anti_affinity))
  selector:
    matchLabels:
      k8s-app: bench-army-knife-agent
      ${selector_key}: "true"
  template:
    metadata:
      name: ${namespace}-agent-host
      namespace: "$namespace"
      labels:
        bench-army-knife-id: "$job_uuid"
        ${selector_key}: "true"
        k8s-app: bench-army-knife-agent
        bench-army-knife-sync: "12"
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: ""
      hostPID: true
      hostNetwork: true
      serviceAccount: ${namespace}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - "bench-army-knife-agent"
            topologyKey: kubernetes.io/hostname
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - "${bm_name}"
            topologyKey: kubernetes.io/hostname
      setHostnameAsFQDN: true
      containers:
      - name: "${namespace}-agent"
        image: "quay.io/rkrawitz/bench-army-knife:latest"
        securityContext:
          privileged: true
        command:
        - "/usr/local/bin/bootstrap.sh"
        args:
        - "$pbench_agent_container_bin"
        - "-u"
        - "-d"
        - "-a"
        - "${namespace}-agent"
        - "-D"
        - "$secret_root/"
        - "-n"
        - "$dnsserver"
        - "-K"
        - "id_rsa_agent"
        - "$port"
        - "${namespace}-controller.$namespace"
        terminationGracePeriodSeconds: 1
        volumeMounts:
        - name: "$secret_name"
          mountPath: "$secret_root"
          defaultMode: 0400
          readOnly: true
      volumes:
      - name: "$secret_name"
        secret:
          defaultMode: 0400
          secretName: "$secret_name"
EOF
    fi
}

function controller_port() {
    clean <<EOF
---
apiVersion: v1
kind: Service
metadata:
  name: "${namespace}-controller"
  namespace: "$namespace"
  labels:
    bench-army-knife-id: "$job_uuid"
    name: ${namespace}-controller
    ${namespace}-controller: "true"
    app: ${namespace}-controller
spec:
  ports:
  - name: ${namespace}-controller
    port: $port
    targetPort: $port
  - name: ssh
    port: $ssh_port
    targetPort: $ssh_port
  - name: redis
    port: $redis_port
    targetPort: $redis_port
  - name: data-sink
    port: $datasink_port
    targetPort: $datasink_port
  type: ClusterIP
  selector:
    name: ${namespace}-controller
EOF
}

function set_controller_hostname() {
    if [[ -n "${hostname:-}" ]] ; then
	clean <<EOF
- "-H"
- "$hostname"
EOF
    fi
}

function controller_affinity() {
    if (( controller_anti_affinity )) ; then
	clean <<EOF
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - "${bm_name}"
      topologyKey: kubernetes.io/hostname
EOF
    fi
}

function mk_podlist() {
    local basename=$1
    local -i pairs=${2:-1};
    local -a podnames=()
    local -i i
    local suffix=
    for i in $(seq 1 "$pairs") ; do
	podnames+=("${basename}-$i${suffix}")
    done
    (IFS=, ; echo "${podnames[*]}")
}

function mk_arglist() {
    local basename=$1
    local -i pairs=${2:-1};
    local -i i
    local suffix=
    for i in $(seq 1 "$pairs") ; do
	echo "- \"${basename}-$i${suffix}\""
    done
}

function mk_jobfile() {
    if [[ -r "$jobfile" ]] ; then
	cat <<EOF
- "--job-file=${secret_root}/${jobfile##*/}"
EOF
    fi
}

function enable_reporting() {
    if ((report_data)) ; then
	cat <<EOF
- "-f"
- "$report_file"
EOF
    fi
}

function controller_pod() {
    #shellcheck disable=SC2155
    local agents=$(oc get pods -l "$selector_key" -A --no-headers 2>/dev/null | wc -l)
    echo "Expect $agents agents" 1>&2
    clean <<EOF
---
apiVersion: v1
kind: Pod
metadata:
  name: "${namespace}-controller"
  namespace: "$namespace"
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  selector:
    matchLabels:
      app: ${namespace}-controller
      name: ${namespace}-controller
  labels:
    bench-army-knife-id: "$job_uuid"
    name: ${namespace}-controller
    app: ${namespace}-controller
    ${namespace}-controller: "true"
    sync: "true"
  openshift.io/scc: privileged
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  terminationGracePeriodSeconds: 1
  restartPolicy: Never
$(indent 2 controller_affinity)
  setHostnameAsFQDN: true
  containers:
  - name: "controller"
    image: "quay.io/rkrawitz/bench-army-knife:latest"
    securityContext:
      privileged: true
    ports:
    - containerPort: $port
      name: controller
    - containerPort: $ssh_port
      name: ssh
    - containerPort: $redis_port
      name: redis
    - containerPort: $datasink_port
      name: datasink
    command:
    - "/usr/local/bin/bootstrap.sh"
    args:
${pre_script:+    - "$secret_root/$pre_script"}
    - "$pbench_controller_bin"
$(indent 4 set_controller_hostname)
    - "-I"
$( (( waitforever )) && echo "    - -w")
    - "${pbench_send_results}"
$(indent 4 enable_reporting)
    - "-L"
    - "$ssh_port"
    - "-D"
    - "$secret_root/"
    - "-K"
    - "id_rsa_agent.pub"
    - "-A"
    - "$agents"
    - "-s"
    - "$port"
    - "-u"
    - "$username"
    - "--"
    - "$pbench_tunnel_bin"
    - "8765"
$(indent 4 mk_arglist "${namespace}" "$instances")
    - "--"
    - "pbench-${bm_name}"
$(indent 4 mk_jobfile)
    - "--config=$configname"
$(indent 4 persistent_volume_extra_args "${namespace}" "$instances")
    - "--unique-ports"
    - "-c"
    - "$(mk_podlist "${namespace}" "$instances")"
$(IFS=$'\n'; echo "${benchmark_args[*]/#/    - \"}" |grep '"' | sed -e 's/$/"/')
    volumeMounts:
    - name: "$secret_name"
      mountPath: "$secret_root"
      readOnly: true
  volumes:
  - name: "$secret_name"
    secret:
      secretName: "$secret_name"
EOF
}

create_credentials

function create_host_addons() {
    local hostname
    for hostname in "${!extra_hosts[@]}" ; do
	echo "-H $hostname=${extra_hosts[$hostname]}"
    done
}

function create_benchmark_objects() {
    create_object controller_port
    local -i i
    local affinity_term=-a
    if (( anti_affinity )) ; then affinity_term=-A; fi
    for i in $(seq 1 "$instances") ; do
	create_object pbench-benchmark-pod -s "$i" "$affinity_term" app-subtype=${bm_name}
    done
    create_object agent_deployment
    if (( ! print_only )) ; then
	while (( $(oc get pods --no-headers -n "$namespace" -l k8s-app="${namespace}-${bm_name}" | wc -l) != instances )) ; do
	    sleep 1
	done
    fi
}

create_benchmark_objects

create_object controller_pod

function monitor_logs() {
    declare -i max_line=0
    local -i lineno=0
    while read -r LINE ; do
	if [[ $LINE =~ ^\.L\.([[:digit:]]{12})(\ .*)?$ ]] ; then
	    lineno=${BASH_REMATCH[1]}
	    if (( lineno > max_line )) ; then
		echo "${BASH_REMATCH[2]}"
		max_line=$lineno
	    fi
	else
	    echo "$LINE"
	fi
    done
}

# shellcheck disable=SC2155
declare -r jq_pbench_cleanup_code=$(cat <<'EOF'
def __walk(f):
  . as $in
  | if type == "object" then
      reduce keys[] as $key
        ( {}; . + { ($key):  ($in[$key] | __walk(f)) } ) | f
  elif type == "array" then map( __walk(f) ) | f
  else f
  end;

__walk(if type == "object" then with_entries(select(.key |test("samples|server_hostname|server_port|uid|iteration_name_format")|not)) else . end) | __walk(if(type == "object" and has("client_hostname") and .client_hostname != "all") then select(.|not) else . end)
EOF
)

function cleanup_report() {
    if (( report_full_timeseries_data)) ; then
	echo "Reporting full data" 1>&2
	cat
    else
	echo "Postprocessing with $jq_pbench_cleanup_code" 1>&2
	jq -r "$jq_pbench_cleanup_code"
    fi
}

function get_pod_uid() {
    local pod=$1
    local ns=${2:-}
    local answer
    answer=$(oc get pod ${ns:+-n "$ns"} "$pod" -ojson 2>/dev/null | jq -r .metadata.uid)
    if [[ -n "$answer" ]] ; then
	echo "$answer"
	return 0
    else
	return 1
    fi
}

function get_pod_phase() {
    local pod=$1
    local uid=$2
    local ns=${3:-}
    read -r answer_uid phase <<< "$(oc get pod ${ns:+-n "$ns"} "$pod" -ojson 2>/dev/null | jq -r '.metadata.uid + " " + .status.phase')"
    if [[ $uid != "$answer_uid" ]] ; then
	return 2
    elif [[ -n "$phase" ]] ; then
	echo "$phase"
	return 0
    else
	return 1
    fi
}

function monitor_reporting_1() {
    local tmp1
    local pod_uid=
    local pod_phase=
    while : ; do
	pod_uid=$(get_pod_uid "${namespace}-controller" "$namespace")
	[[ -n "$pod_uid" ]] && break
	sleep 5
    done
    debug ">>> Waiting for pod to start running"
    while : ; do
	pod_phase=$(get_pod_phase "${namespace}-controller" "$pod_uid" "$namespace")
	case "$?" in
	    2) fatal "Pod $namespace/${namespace}-controller is not the same pod it originally was!" ;;
	    1) fatal "Cannot get status for pod $namespace/${namespace}-controller" ;;
	    0)
		debug " >> phase is ${pod_phase}"
		case "${pod_phase,,}" in
		    running) break ;;
		    error) fatal "Pod $namespace/${namespace}-controller failed!" ;;
		    *) debug "Waiting for pod $namespace/${namespace}-controller to run ($pod_phase)" ;;
		esac
		;;
	    *) fatal "Unexpected status $? from pod phase check" ;;
	esac
	sleep 5
    done

    debug ">>> pod is running, waiting for payload retrieval"
    tmp1=$(mktemp "/tmp/bench-army-knife${bm_name:+-$bm_name}-resultsXXXXXX.json")
    # TODO Need a better check here.
    while : ; do
	pod_phase=$(get_pod_phase "${namespace}-controller" "$pod_uid" "$namespace")
	case "$?" in
	    2) fatal "Pod $namespace/${namespace}-controller is not the same pod it originally was!" ;;
	    1) fatal "Cannot get status for pod $namespace/${namespace}-controller" ;;
	    0)
		debug " >> pod phase is $pod_phase"
		if [[ ${pod_phase,,} = running ]] ; then
		    # It's possible that the pod will go away between the probe and payload retrieval.
		    # That's OK; this will fail, and the next time around we'll pick up that it failed.
		    if oc rsh -T -n "$namespace" "${namespace}-controller" sh -c "cat '$report_file'" > "$tmp1" 2>/dev/null ; then
			debug "  > found report file $report_file"
			# I've seen a few cases where apparently this command succeeded, even though the file
			# didn't really exist.  The scenario appears to be a connection reset in the retrieval
			# command.  So wait a few seconds to make sure that this was real.
			sleep 5
			oc rsh -T -n "$namespace" "${namespace}-controller" test -f "$report_file" >/dev/null 2>&1 && break
			# In that case, try again.
			echo "*** Report file $report_file vanished unexpectedly!" 1>&2
		    fi
		    sleep 5
		else
		    fatal "Pod $namespace/${namespace}-controller died prematurely!"
		fi
		;;
	    *) fatal "Unexpected status $? from pod phase check" ;;
	esac
    done
    debug ">>> Have report file, waiting to clean up"
    # At this point, we have the report file.  Clear it out and keep monitoring until the pod goes away.
    while : ; do
	# Keep trying to remove it unconditionally until the pod goes away.
	# This is in case something on the pod somehow tries to recreate the report file
	# and the controller then never sees it gone.
	oc rsh -T -n "$namespace" "${namespace}-controller" sh -c "rm -f '$report_file'" 2>/dev/null
	pod_phase=$(get_pod_phase "${namespace}-controller" "$pod_uid" "$namespace")
	case "$?" in
	    2) fatal "Pod $namespace/${namespace}-controller is not the same pod it originally was!" ;;
	    1) fatal "Cannot get status for pod $namespace/${namespace}-controller" ;;
	    0) if [[ ${pod_phase,,} = running ]] ; then
		   debug " >> Still running"
		   break
	       fi
	       debug " >> Pod no longer running, $pod_phase"
	       ;;
	    *) fatal "Unexpected status $? from pod phase check" ;;
	esac
	sleep 5
    done
    cat "$tmp1"
    rm -f "$tmp1"
    return 0
}

function monitor_reporting() {
    local tmp
    tmp=$(mktemp "/tmp/bench-army-knife${bm_name:+-$bm_name}XXXXXX.json")
    # shellcheck disable=SC2064
    trap "rm -f $tmp" INT TERM EXIT
    # It's unfortunate to create a temporary file here, but we need to hold off
    # on trying to retrieve the underlying objects until monitoring is complete.
    # Otherwise we might not retrieve all of the objects, or we might get them
    # in an earlier state.
    monitor_reporting_1 </dev/null | cleanup_report > "$tmp"
    jq -c --slurpfile objects <(oc get all -A -l "bench-army-knife-id=$job_uuid" -o json) '{results: .results, api_objects: [$objects[].items?[] | { kind: .kind, name: .metadata.name, namespace: .metadata.namespace}]}' < "$tmp" 1>&3
    rm -f "$tmp"
}

function monitor_pod() {
    local pod=$1
    local ns=${2:+-n $2}
    local container=${3:+-c $3}
    local -i lines_printed=0
    local -i report_monitor_pid=0

    while : ; do
	# shellcheck disable=SC2086
	status=$(oc get pod $ns $pod --no-headers -o custom-columns='status:.status.phase')
	case "${status,,}" in
	    pending|unknown)
		echo "Waiting for $pod to start ($status)..."
		sleep 10
		;;
	    failed)
		echo "Controller pod failed"
		return 1
		;;
	    succeeded|running)
		if [[ $report_data -gt 0 && ${status,,} = running && $report_monitor_pid -eq 0 ]] ; then
		    monitor_reporting 1>&3 &
		    report_monitor_pid=$!
		    trap '[[ -n "$(jobs -p)" ]] && kill "$(jobs -p)"' TERM INT EXIT
		fi
		# shellcheck disable=SC2086
		oc logs -f $ns $pod $container | while read -r LINE ; do
		    printf ".L.%012o %s\n" $((++lines_printed)) "$LINE"
		done
		if [[ ${status,,} = succeeded ]] ; then
		    echo "Run completed successfully"
		    return 0
		fi
		sleep 5
		;;
	    *)
		echo "Unknown status $status"
		sleep 30
		;;
	esac
    done
}

(( print_only )) || (monitor_pod "${namespace}-controller" "$namespace" 2>&1 | monitor_logs 1>&2) 3>&1
