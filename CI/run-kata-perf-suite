#!/bin/bash

# Copyright 2022 Robert Krawitz/Red Hat
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -u

declare OC=${OC:-${KUBECTL:-}}
OC=${OC:-$(type -p oc)}
OC=${OC:-$(type -p kubectl)}	# kubectl might not work, though...
CLUSTERBUSTER="$(realpath "$(dirname "$(realpath -e "$0")")/../clusterbuster")"

declare -A profiles=()
files_runs_auto=$(echo files-params={1,4}:256:256:{4096:{0,4096,262144},65536:262144}:{0,1})
profiles[auto]="job_runtime=120 fio-fdatasync=0 job-timeout=9000 fio-max-relative-filesize=0.25 fio-memsize=4096 artifactdir= virtiofsd-direct restart use-python-venv $files_runs_auto"

declare client_pin_node=
declare server_pin_node=
declare sync_pin_node=
declare -i job_runtime=120
declare -i job_timeout=-1200
declare artifactdir=
declare report_format=none
declare -i report_object_creation=0
declare -i cleanup=0
declare dontdoit=
declare -i run_timeout=0
declare -i monitor_pid=0
declare -i force_pull_image=0
declare job_pid=
declare -i use_python_venv=1
declare python_venv=
declare basename=

declare -a workloads=(scaling uperf fio files)
declare -a runtimeclasses=('' 'kata')

declare -i scaling_starting_namespaces=1
declare -i scaling_deps_per_namespace=5
declare -i scaling_max_namespaces=-1
declare -i scaling_job_runtime=0
declare -i scaling_job_timeout=0

declare -a uperf_msg_sizes=(64 1024 8192)
declare -a uperf_nthrs=(1 4)
declare -a uperf_ninst=(1 4)
declare -a uperf_test_types=(stream rr)
declare -i uperf_job_runtime=0
declare -i uperf_job_timeout=0

declare -a fio_blocksizes=(1048576 4096)
declare -a fio_patterns=(read write randread randwrite readwrite randrw)
declare -a fio_directs=(1)
declare -a fio_fdatasyncs=(0)
declare -a fio_iodepths=(1 4)
declare -a fio_ioengines=(sync libaio)
declare -a fio_ninst=(1 4)
declare -i fio_job_runtime=0
declare fio_workdir=/var/tmp
declare -i fio_absolute_filesize=0
declare -i fio_max_absolute_filesize=0
declare fio_relative_filesize=2
declare fio_max_relative_filesize=$fio_relative_filesize
declare -i fio_node_memory=0
declare -i fio_ramptime=5
declare -i fio_job_timeout=9000
declare -i fio_pod_memsize=

declare -a files_ninst=(1 4)
declare -a files_dirs_per_volume=(256)
declare -a files_per_dir=(256)
declare -a files_block_size=(4096 65536)
declare -a files_sizes=(0 4096 $((256 * 1024)))
declare -a files_directs=(0 1)
declare -i files_job_timeout=9000
declare -a files_params=()
declare -i files_min_direct=1024
declare -i virtiofsd_direct=1
declare -i virtiofsd_writeback=0
declare -i virtiofsd_threadpoolsize=0

declare -i fail=0
declare -i counter=0
declare -i hard_fail_on_error=0
declare -i restart=0

declare -a failures=()
declare -a jobs=()
declare -A job_runtimes=()

declare starting_timestamp=
declare job_datestamp

function finis() {
    if [[ -n "$job_pid" ]] ; then
	kill $job_pid
	wait "$job_pid"
	job_pid=
    fi
    if [[ -n "${starting_timestamp:-}" && $$ -eq "$BASHPID" ]] ; then
	local ending_timestamp
	ending_timestamp=$(date +%s)

	echo "Run times:"
	local job
	for job in "${jobs[@]}" ; do
	    printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	done
	if [[ -n "${failures[*]}" ]] ; then
	    echo "Failing jobs:"
	    for job in "${failures[@]}" ; do
		printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	    done
	    fail=1
	fi

	echo "Run took $(to_hms "$starting_timestamp" "$ending_timestamp")"
	starting_timestamp=
    fi
    if [[ -n "$python_venv" && -d "$python_venv" ]] ; then
	deactivate
	rm -rf "$python_venv"
    fi
    exit $fail
}

function fatal() {
    echo "$*" 1>&2
    fail=1
    finis
}

function bool() {
    local value
    for value in "$@" ; do
	case "${value,,}" in
	    ''|1|y|yes|tru*) echo 1 ;;
	    *)               echo 0 ;;
	esac
    done
}

function parse_size() {
    local size
    local sizes=$*
    sizes=${sizes//,/ }
    for size in $sizes ; do
	if [[ $size =~ (-?[[:digit:]]+)([[:alpha:]]*) ]] ; then
	    local size=${BASH_REMATCH[1]}
	    local size_modifier=${BASH_REMATCH[2],,}
	    local -i size_multiplier=1
	    case "$size_modifier" in
		''|b)             size_multiplier=1              ;;
		k|kb|kilobytes)   size_multiplier=1000           ;;
		ki|kib|kibibytes) size_multiplier=1024           ;;
		m|mb|megabytes)   size_multiplier=1000000        ;;
		mi|mib|mebibytes) size_multiplier=1048576        ;;
		g|gb|gigabytes)   size_multiplier=1000000000     ;;
		gi|gib|gibibytes) size_multiplier=1073741824     ;;
		t|tb|terabytes)   size_multiplier=1000000000000  ;;
		ti|tib|tebibytes) size_multiplier=1099511627776  ;;
		*) fatal "Cannot parse size $optvalue"           ;;
	    esac
	    echo -n "$((size*size_multiplier)) "
	else
	    fatal "Cannot parse size $optvalue"
	fi
    done
}

function parse_option() {
    local option=$1
    option=${option## }
    option=${option%% }
    if [[ $option =~ ^([^=]+)\ *=\ *([^\ ].*)? ]] ; then
	option="${BASH_REMATCH[1]}=${BASH_REMATCH[2]}"
    fi
    [[ -n "$option" ]] || return
    local optname
    local optvalue
    optname=${option%%=*}
    optname=${optname,,}
    optvalue=${option#*=}
    noptname=${optname//-/_}
    if [[ $option != *'='* ]] ; then
	if [[ $noptname = "no_"* || $optname = "dont_"* ]] ; then
	    noptname=${noptname#dont_}
	    noptname=${noptname#no_}
	    optvalue=0
	else
	    optvalue=1
	fi
    fi
    local noptname1=${noptname//_/}
    echo "$noptname1 $noptname $optvalue"
}

function parse_time() {
    local time=$1
    local -a times=(${time//:/ })
    local -i d=0
    local -i h=0
    local -i m=0
    local -i s=0
    case "${#times[@]}" in
	1)
	    s=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	2)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	3)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	4)
	    d=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    h=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[3]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	*)
	    fatal "Malformed time $time"
	    ;;
    esac
    echo "$(( (d * 86400) + (h * 3600) + (m * 60) + s ))"
}

function splitarg() {
    echo "${*//,/ }"
}

function set_pin_nodes() {
    if [[ -z "$client_pin_node" || -z "$server_pin_node" || -z "$sync_pin_node" ]] ; then
	local -a nodes
	# shellcheck disable=SC2207
	nodes=($(${OC} get node -l node-role.kubernetes.io/worker= -o jsonpath='{.items[*].metadata.name}'))
	local -i node_count=${#nodes[@]}
	[[ -z "$client_pin_node" ]] && client_pin_node=${nodes[$((0 % node_count))]}
	[[ -z "$server_pin_node" ]] && server_pin_node=${nodes[$((1 % node_count))]}
	[[ -z "$sync_pin_node" ]] && sync_pin_node=${nodes[$((2 % node_count))]}
    fi
}

function get_node_memory() {
    local node=$1
    local mem
    mem=$(oc get node "$node" -ojsonpath='{.status.allocatable.memory}')
    parse_size "$mem"
}

function process_profile() {
    local profile=$1
    if [[ -n "${profiles[$profile]}" ]] ; then
	local arg
	for arg in ${profiles[$profile]} ; do
	    process_option "$arg"
	done
    fi
}

function force_pull_base_image() {
    for n in $(oc get node --no-headers |awk '{print $1}') ; do
	oc debug --no-stdin=true --no-tty=true node/"$n" -- chroot /host podman pull quay.io/rkrawitz/bench-army-base &
    done
    wait
    for n in $(oc get node --no-headers |awk '{print $1}') ; do
	oc debug --no-stdin=true --no-tty=true node/"$n" -- chroot /host podman pull quay.io/rkrawitz/bench-army-knife &
    done
    wait
}

function monitor_1() {
    local timeout=${1:-$run_timeout}
    if ((timeout <= 0)) ; then
	timeout=infinity
    fi
    # Allow the main process to catch these signals and terminate us.
    # However, allow SIGHUP through so that if we get hung up on we'll
    # safely exit.
    trap true TERM INT
    sleep "$timeout"
    kill -USR1 $$
}

function monitor() {
    (monitor_1 "$@") &
    monitor_pid=$!
}

function help() {
    ${PAGER:-less} <<EOF
Usage: $0 [options] [tests]
    Tests may be one or more of scaling, uperf, fio, and files.  If not
        provided, all tests are run.

    General options:

        clientpin=<node>        Pin client pods to the specified node.
				If not provided, the first worker node
				(in the order returned by `oc get nodes')
				is used.
        serverpin=<node>	Pin server pods to the specified node.
				By default, the second worker node is used.
        syncpin=<node>		Pin the sync pod to the specified node.
				By default, the third worker node is used.
	runtime=<seconds>	Run the job for the given number of seconds,
				if applicable (this does not apply to the
				files test).  May be overridden by
				workload-specific values.
	timeout=<seconds>	Time the job out after the given number of
				seconds.  May be overridden by
				workload-specific values.
	artifactdir=<dir>	Store all run artifacts in the specified
				directory.  Individual runs are in
				subdirectories.
	reportformat=<format>	Format of report printed during run.
				Default none.  Options are as in clusterbuster.
	runtimeclasses=<classes>
				Comma-separated list of runtime classes to test.
				Default is <empty> (i. e. default) and kata.
        reportobjectcreation	Whether to report object creation.
	cleanup			Clean up all pods after last run.
	restart			Restart any failed or incomplete jobs from a
				prior run.  Default is no.  Can only be used
				with identical parameters to previous run.
	profile=<profile>	Which profile to use.  Only current option
				is auto.  Default is no profile.

    Virtiofsd configuration options (for kata):
	virtiofsd-direct	Allow direct I/O requests from guest to operate
				as such.  Default is yes (NOT the kata default)
	virtiofsd-writeback	Use write back caching for virtiofsd.  Default
				is no.
	virtiofsd-threadpoolsize=n
				Use the specified thread pool size for
				virtiofsd.  Default is unset (equivalent to 1).

    Scaling test options:
	scaling-starting-namespaces=n
				Start the test with the specified number of
				namespaces, incrementing until failure.
				Default 1.
	scaling-deps-per-namespace=n
				Deploy the specified number of pods per
				namespace.  Default is 5.
	scaling-runtime=<seconds>
				Allow the pods to run for the specified time.
				Default is 0.  Typically set to 60 to collect
				reliable metrics data.
	scaling-timeout=<seconds>
				Time the job out after specified time.  Default
				is the global timeout default.

    Uperf options


EOF
}

function process_option() {
    local noptname
    local noptname1
    local optvalue
    read -r noptname1 noptname optvalue <<< "$(parse_option "$1")"
    optvalue=$(splitarg "$optvalue")
    case "$noptname1" in
	clientpin*) client_pin_node=$optvalue						;;
	serverpin*) server_pin_node=$optvalue						;;
	syncpin*) sync_pin_node=$optvalue						;;
	jobruntime|runtime) job_runtime=$optvalue					;;
	jobtimeout|timeout) job_timeout=$optvalue					;;
	artifactdir) artifactdir="${optvalue:-${artifactdir:-$(pwd)}}"			;;
	reportformat*) report_format=$optvalue						;;
	runtimeclass*) readarray -t runtimeclasses <<< "$optvalue"			;;
	reportobject*) report_object_creation=$(bool "$optvalue")			;;
	cleanup*) cleanup=$(bool "$optvalue")						;;
	restart) restart=$(bool "$optvalue")						;;
	runtimeout) run_timeout=$(parse_time "$optvalue")				;;
	profile) process_profile "$optvalue"						;;
	forcepull*) force_pull_image="$(bool "$optvalue")"				;;
	usepythonvenv*) use_python_venv="$(bool "$optvalue")"				;;
	basename) basename=$optvalue							;;

	virtiofsdwriteback) virtiofsd_writeback=$(bool "$optvalue")			;;
	virtiofsddirect) virtiofsd_direct=$(bool "$optvalue")				;;
	virtiofsdthreadpool) virtiofsd_threadpoolsize=$optvalue				;;

	scalingstarting*) scaling_starting_namespaces=$optvalue				;;
	scalingdeps*) scaling_deps_per_namespace=$optvalue				;;
	scaling*runtime) scaling_job_runtime=$optvalue					;;
	scaling*timeout) scaling_job_timeout=$optvalue					;;
	scalingmax*) scaling_max_namespaces=$optvalue					;;

	uperfmsg*) readarray -t uperf_msg_sizes <<< "$(parse_size "$optvalue")"		;;
	uperfnthr*) readarray -t uperf_nthrs <<< $(parse_size "$optvalue")		;;
	uperfninst*) readarray -t uperf_ninst <<< "$(parse_size "$optvalue")"		;;
	uperftest*) readarray -t uperf_test_types <<< "$(parse_size "$optvalue")"	;;
	uperf*runtime) uperf_job_runtime=$optvalue					;;
	uperf*timeout) uperf_job_timeout=$optvalue					;;

	fioblock*) readarray -t fio_blocksizes <<< "$(parse_size "$optvalue")"		;;
	fiopat*) readarray -t fio_patterns <<< "$(parse_size "$optvalue")"		;;
	fiodirect*) readarray -t fio_directs <<< "$(bool "$optvalue")"			;;
	fiofdatasync*) readarray -t fio_fdatasyncs <<< "$(bool "$optvalue")"		;;
	fioiodepth*) readarray -t fio_iodepths <<< "$(parse_size "$optvalue")"		;;
	fioioeng*) readarray -t fio_ioengines <<< "$optvalue"				;;
	fioninst*) readarray -t fio_ninst <<< "$(parse_size "$optvalue")"		;;
	fioworkdir) fio_workdir=$optvalue						;;
	fio*runtime) fio_job_runtime=$optvalue						;;
	fioramp*) fio_ramptime=$optvalue						;;
	fioabs*file*) fio_absolute_filesize=$(parse_size "$optvalue")			;;
	fiomaxabs*file*) fio_max_absolute_filesize=$(parse_size "$optvalue")		;;
	fiorel*file*) fio_relative_filesize="$optvalue"					;;
	fiomaxrel*file*) fio_max_relative_filesize="$optvalue"				;;
	fio*timeout) fio_job_timeout=$optvalue						;;
	fio*memsize) fio_pod_memsize=$(parse_size "$optvalue")				;;

	filesninst*) readarray -t files_ninst <<< "$(parse_size "$optvalue")"		;;
	filesdirs*) readarray -t files_dirs_per_volume <<< "$(parse_size "$optvalue")"	;;
	filesperdir*) readarray -t files_per_dir <<< "$(parse_size "$optvalue")"	;;
	filesblocksize*) readarray -t files_block_size <<< "$(parse_size "$optvalue")"	;;
	filessize*) readarray -t files_sizes <<< "$(parse_size "$optvalue")"		;;
	filesdirect*) readarray -t files_directs <<< "$(bool "$optvalue")"		;;
	files*timeout) files_job_timeout=$optvalue					;;
	files*params) files_params+=(${optvalue//,/ })					;;
	filesmindir*) files_min_direct=$(parse_size "$optvalue")			;;

	*) fatal "Unknown option --$1"							;;
    esac
}

while getopts 'hn-:B:' opt ; do
    case "$opt" in
	-) process_option "$OPTARG"	;;
	h) echo "help"; exit 1		;;
	n) dontdoit=-n			;;
	B) basename=$OPTARG		;;
	*)				;;
    esac
done
shift $((OPTIND - 1))
if [[ -n "$*" ]] ; then
    workloads=("$@")
fi

function compute_timeout() {
    local -i timeout=$1
    ((timeout <= 0)) && timeout=$job_timeout
    ((timeout < 0)) && timeout=$((-timeout))
    echo "$timeout"
}

((scaling_job_runtime <= 0)) && scaling_job_runtime=$job_runtime
scaling_job_timeout=$(compute_timeout "$scaling_job_timeout")

((uperf_job_runtime <= 0)) && uperf_job_runtime=$job_runtime
uperf_job_timeout=$(compute_timeout "$uperf_job_timeout")

((fio_job_runtime <= 0)) && fio_job_runtime=$job_runtime
fio_job_timeout=$(compute_timeout "$fio_job_timeout")

files_job_timeout=$(compute_timeout "$files_job_timeout")

set_pin_nodes

fio_node_memory=$(get_node_memory "$client_pin_node")

if [[ -z "${files_params[*]}" ]] ; then
    for ninst in "${files_ninst[@]}" ; do
	for dirs in "${files_dirs_per_volume[@]}" ; do
	    for files in "${files_per_dir[@]}" ; do
		for blocksize in "${files_block_size[@]}" ; do
		    for size in "${files_sizes[@]}" ; do
			for direct in "${files_directs[@]}" ; do
			    if ((! direct || blocksize >= files_min_direct)) ; then
				files_params+=("${ninst}:${dirs}:${files}:${blocksize}:${size}:${direct}")
			    fi
			done
		    done
		done
	    done
	done
    done
fi

function computeit() {
    bc <<< "$1" | sed -e 's/\..*$//'
}

((fio_absolute_filesize <= 0)) && fio_absolute_filesize=$(computeit "$fio_node_memory * $fio_relative_filesize")
((fio_max_absolute_filesize <= 0)) && fio_max_absolute_filesize=$(computeit "$fio_node_memory * $fio_max_relative_filesize")

function python_create_venv() {
    local dir=$1
    python3 -m venv "$1" || fatal "Can't create venv!"
    . "$1/bin/activate" || fatal "Can't activate venv!"
    python3 -m pip -q install --upgrade pip || fatal "Can't upgrade pip!"
    pip3 -q install prometheus-api-client==0.5.0 openshift-client==1.0.14 Jinja2==3.0.1 || fatal "Can't install Python packages!"
}

function to_hms() {
    local -i start=$1
    local -i end=$2
    local -i interval=$((end-start))

    local -i h=$((interval / 3600))
    local -i m=$(((interval % 3600) / 60))
    local -i s=$((interval % 60))
    if ((h > 0)) ; then
	printf "%d:%02d:%02d\n" "$h" "$m" "$s"
    else
	printf "%d:%02d\n" "$m" "$s"
    fi
}

function xruntimeclass() {
    local runtimeclass=$1
    if [[ $runtimeclass == kata ]] ; then
	echo kata
    else
	echo nonkata
    fi
}

function doit() {
    echo "$*"
    "$@" &
    job_pid=$!
    wait "$job_pid"
    local status=$?
    job_pid=
    return $status
}

function run_clusterbuster() {
    local OPTIND=0
    local opt
    local -i error_is_failure=1
    local jobdir=
    local tmp_jobdir=
    local jobname=
    local runtimeclass=
    local workload=
    local timeout=
    while getopts 'ynj:r:w:t:' opt "$@" ; do
	case "$opt" in
	    y) error_is_failure=0	;;
	    n) error_is_failure=1	;;
	    j) jobname="$OPTARG"	;;
	    r) runtimeclass="$OPTARG"	;;
	    w) workload="$OPTARG"	;;
	    t) timeout="$OPTARG"	;;
	    *)				;;
	esac
    done
    [[ -z "$jobname" ]] && fatal "Job name must be specified"
    [[ -z "$workload" ]] && fatal "Workload must be specified"
    jobname=$(printf '%s-%s-%04d-%s' "$workload" "$(xruntimeclass "$runtimeclass")" "$counter" "$jobname")
    jobdir=${artifactdir:+$artifactdir/$jobname}
    counter=$((counter+1))
    if [[ -n "$jobdir" && -d "$jobdir" ]] ; then
	if ((restart)) ; then
	    echo "$jobname is already present"
	    return 0
	else
	    rm -rf "$jobdir"
	fi
    fi
    tmp_jobdir="${jobdir:+${jobdir}.tmp}"

    shift $((OPTIND-1))
    local -i status=0
    local -i job_start
    local -i job_end
    job_start=$(date +%s)
    echo
    echo "*** Running $jobname"
    # shellcheck disable=SC2090
    doit "$CLUSTERBUSTER" ${dontdoit:+"$dontdoit"} \
	 ${basename:+"--basename=$basename"} \
	 --precleanup --cleanup="$cleanup" --image-pull-policy=IfNotPresent \
	 --metrics --report="$report_format" --workload="$workload" \
	 ${job_runtime:+"--workload_runtime=$job_runtime"} \
	 ${client_pin_node:+"--pin-node=client=$client_pin_node"} \
	 ${server_pin_node:+"--pin-node=server=$server_pin_node"} \
	 ${sync_pin_node:+"--pin-node=sync=$sync_pin_node"} \
	 ${timeout:+"--timeout=$timeout"} \
	 ${jobname:+"--jobname=$jobname"} \
	 ${tmp_jobdir:+"--artifactdir=$tmp_jobdir"} \
	 ${runtimeclass:+"--runtimeclass=$runtimeclass"} \
	 --virtiofsd_direct="$virtiofsd_direct" \
	 --virtiofsd_writeback="$virtiofsd_writeback" \
	 --virtiofsd_threadpoolsize="$virtiofsd_threadpoolsize" \
	 --report_object_creation="$report_object_creation" \
	 "$@" || status=$?
    job_end=$(date +%s)
    job_runtimes[$jobname]="$(to_hms "$job_start" "$job_end")"
    if ((status == 0)) ; then
	jobs+=("$jobname")
	if [[ -n "$jobdir" ]] ; then
	    [[ -d "$jobdir" ]] && fatal "$jobdir exists (shouldn't!)"
	    mv "$tmp_jobdir" "$jobdir" || fatal "Can't rename $tmp_jobdir to $jobdir"
	fi
    else
	((error_is_failure)) && failures+=("$jobname")
	if [[ -n "$jobdir" ]] ; then
	    local fail_jobdir_base="${jobdir}.FAIL"
	    local fail_jobdir=$fail_jobdir_base
	    local -i jobdir_idx=1
	    while [[ -d "$fail_jobdir" ]] ; do
		fail_jobdir="${fail_jobdir_base}.$jobdir_idx"
		jobdir_idx=$((jobdir_idx+1))
	    done
	    mv "$tmp_jobdir" "$fail_jobdir" || fatal "Can't rename $tmp_jobdir to $fail_jobdir"
	fi
	((hard_fail_on_error)) && finis
    fi
    return $status
}

function test_scaling() {
    local runtimeclass=$1
    namespaces=$scaling_starting_namespaces
    while ((scaling_max_namespaces == -1 || namespaces <= scaling_max_namespaces)); do
	job_name="$((namespaces*scaling_deps_per_namespace))"
	echo "*** Running $((namespaces * scaling_deps_per_namespace)) pods"
	if run_clusterbuster -y -j "$job_name" -w cpusoaker -r "$runtimeclass" -t "$scaling_job_timeout" -- \
			     --deployments="$scaling_deps_per_namespace" \
			     --namespaces="$namespaces" --objs_per_call=6 --parallel=100 ; then
	    namespaces=$((namespaces+1))
	else
	    echo "Run failed: $?"
	    break
	fi
    done
    echo Done
}

function test_uperf() {
    local runtimeclass=$1
    local -i msg_size
    local -i nthr
    local -i ninst
    local test_type
    for msg_size in "${uperf_msg_sizes[@]}" ; do
	for nthr in "${uperf_nthrs[@]}" ; do
	    for ninst in "${uperf_ninst[@]}" ; do
		for test_type in "${uperf_test_types[@]}" ; do
		    job_name="${msg_size}B-${nthr}i-${ninst}P-${test_type}"
		    run_clusterbuster -j "$job_name" -w uperf -r "$runtimeclass" -t "$uperf_job_timeout" -- \
				      --deployments="$ninst" \
				      --uperf_msg_size="$msg_size" \
				      --uperf_test_type="$test_type" \
				      --uperf_proto=tcp \
				      --uperf_nthr="$nthr" \
				      --pod-annotation="io.katacontainers.config.hypervisor.default_vcpus: \"$nthr\""
		done
	    done
	done
    done
}

function test_fio() {
    local runtimeclass=$1
    local -i ninst
    local memory_annotation=
    if ((fio_pod_memsize > 0)) ; then
	# shellcheck disable=SC2089
	memory_annotation=--pod-annotation="io.katacontainers.config.hypervisor.default_memory: \"$fio_pod_memsize\""
    fi
    for ninst in "${fio_ninst[@]}" ; do
	local filesize
	filesize=$(computeit "$fio_absolute_filesize / $ninst")
	if ((filesize > fio_max_absolute_filesize)) ; then
	    filesize=$fio_max_absolute_filesize
	fi
	job_name="fio-${ninst}P"
	# shellcheck disable=SC2090
	run_clusterbuster -j "$job_name" -w fio -r "$runtimeclass" -t "$fio_job_timeout" -- \
			  --deployments="$ninst" \
			  --fio-blocksize="$(IFS=,; echo "${fio_blocksizes[*]}")" \
			  --fio-patterns="$(IFS=,; echo "${fio_patterns[*]}")" \
			  --fio-ioengines="$(IFS=,; echo "${fio_ioengines[*]}")" \
			  --fio-iodepths="$(IFS=,; echo "${fio_iodepths[*]}")" \
			  --fio-fdatasyncs="$(IFS=,; echo "${fio_fdatasyncs[*]}")" \
			  --fio-directs="$(IFS=,; echo "${fio_directs[*]}")" \
			  --fio_filesize="$filesize" \
			  --fio_ramp_time="$fio_ramptime" \
			  --fio_workdir="$fio_workdir" \
			  ${memory_annotation:+"$memory_annotation"}
    done
}

function test_files() {
    local runtimeclass=$1
    local -i ninst
    local files_dirs_per_volume
    local files_per_dir
    local files_block_size
    local file_size
    local files_direct
    local options
    for options in "${files_params[@]}" ; do
	read -r ninst files_dirs_per_volume files_per_dir files_block_size file_size files_direct <<< "$(parse_size ${options//:/ })"
	if [[ -z "$files_direct" ]] ; then
	    echo "Unparsable options $options" 1>&2
	    continue
	fi
	if ((files_block_size > file_size && file_size > 0)) ; then
	    files_block_size=$file_size
	fi
	job_name="files-${ninst}P-${files_dirs_per_volume}D-${files_per_dir}F-${files_block_size}B-${file_size}S-${files_direct}T"
	# shellcheck disable=SC2090
	run_clusterbuster -j "$job_name" -w files -r "$runtimeclass" -t "$files_job_timeout" -- \
			  --deployments="$ninst" \
			  --dirs_per_volume="$files_dirs_per_volume" \
			  --files_per_dir="$files_per_dir" \
			  --file_block_size="$files_block_size" \
			  --files_direct="$files_direct" \
			  --filesize="$file_size"
    done
}

if ((use_python_venv)) ; then
    python_venv=$(mktemp -d -t "cb-ci-venv.XXXXXXXX")
    python_create_venv "$python_venv"
fi
monitor "$run_timeout"
trap "if ((monitor_pid > 0)) ; then kill -9 $monitor_pid; fi; echo Run timed out after $run_timeout seconds; fail=3; finis" USR1
trap 'if ((fail < 2)) ; then kill -9 $monitor_pid; fail=2; fi; finis' TERM INT HUP
trap 'finis' EXIT
if ((force_pull_image)) ; then
    force_pull_base_image
fi
starting_timestamp=$(date +%s)
job_datestamp=$(date -u '+%Y_%m_%dT%H_%M_%S%z' --date=@"$starting_timestamp")
artifactdir=${artifactdir//%s/$job_datestamp}

for runtimeclass in "${runtimeclasses[@]}" ; do
    for workload in "${workloads[@]}" ; do
	# Use a separate counter for each workload/runtime
	counter=0
	case "$workload" in
	    scal*) test_scaling "$runtimeclass" ;;
	    uperf) test_uperf "$runtimeclass" ;;
	    fio) test_fio "$runtimeclass" ;;
	    files) test_files "$runtimeclass" ;;
	    *) fatal "Unknown workload $workload" ;;
	esac
    done
done
