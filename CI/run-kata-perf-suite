#!/bin/bash

# Copyright 2022 Robert Krawitz/Red Hat
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

declare -i set_u_works=1
if (( BASH_VERSINFO[0] >= 5 || (BASH_VERSINFO[0] == 4 && BASH_VERSINFO[1] >= 4) )) ; then
    set -u
else
    set_u_works=0
    cat 1>&2 <<EOF
Warning: bash version at least 4.4 is recommended for using ${0##*/}.
Actual version is ${BASH_VERSION}
EOF
fi

declare OC=${OC:-${KUBECTL:-}}
OC=${OC:-$(type -p oc)}
OC=${OC:-$(type -p kubectl)}	# kubectl might not work, though...
declare __topdir__
__topdir__="$(realpath "$(dirname "$(realpath -e "$0")")/..")"
declare __libdir__="${__topdir__}/lib/clusterbuster"
declare __clusterbuster__="${__topdir__}/clusterbuster"
declare __analyze__="${__topdir__}/analyze-clusterbuster-report"
declare __profiledir__="${__libdir__}/CI/profiles"
declare __workloaddir__="${__libdir__}/CI/workloads"

[[ -d "$__libdir__" ]] || fatal "Can't find my library dir!"

. "${__libdir__}"/libclusterbuster.sh
load_workloads "$__workloaddir__"

declare client_pin_node=
declare server_pin_node=
declare sync_pin_node=
declare -i job_runtime=120
declare -i job_timeout=-1200
declare artifactdir=
declare report_format=none
declare analysis_format=
declare -i report_object_creation=0
declare -i cleanup=0
declare dontdoit=
declare -i run_timeout=0
declare -i monitor_pid=0
declare -i force_pull_image=0
declare job_pid=
declare -i use_python_venv=1
declare python_venv=
declare basename=
declare analyze_results=
declare -i debugonly=0
declare force_cleanup_timeout=
declare -i take_prometheus_snapshot=0
declare snapshot_date_format='%Y_%m_%dT%H_%M_%S%z'
declare prometheus_snapshot_start_ts=

declare -a runtimeclasses=('' 'kata')

declare -i virtiofsd_direct=1
declare -i virtiofsd_writeback=0
declare -i virtiofsd_threadpoolsize=0

declare -i fail=0
declare -i interrupted=0
declare -i timedout=0
declare -i counter=0
declare -i hard_fail_on_error=0
declare -i restart=0
# shellcheck disable=2155
declare uuid=$(uuidgen -r)

declare -a failures=()
declare -a jobs=()
declare -A job_runtimes=()

declare starting_timestamp=
declare job_datestamp

function report_results() {
    if [[ -n "$*" ]] ; then
	local -a results=("${@/#/    \"}")
	results=("${results[@]/%/\"}")
	local result
	result="$(IFS=","; echo "${results[*]}")"
	echo "${result//,/,$'\n'}"
    fi
}

function retrieve_prometheus_timestamp() {
    "${OC}" exec -n openshift-monitoring prometheus-k8s-0 -- /bin/sh -c "date -u '+$snapshot_date_format'"
}
    
function start_prometheus_snapshot() {
    echo "Starting Prometheus snapshot" 1>&2
    "${OC}" delete pod -n openshift-monitoring prometheus-k8s-0
    local -i retry=12
    until "${OC}" get pod -n openshift-monitoring prometheus-k8s-0 >/dev/null 2>&1 ; do
	echo "Promtheus pod did not start, $retry attempt(s) left" 1>&2
	((retry > 0)) || fatal "Prometheus pod did not restart!"
	retry=$((retry-1))
	sleep 5
    done
    "${OC}" wait --for=condition=Ready -n openshift-monitoring pod/prometheus-k8s-0 || fatal "Prometheus pod did not become ready"
    # Wait for prometheus pod to fully initialize
    sleep 60
    prometheus_snapshot_start_ts=$(retrieve_prometheus_timestamp) || fatal "Unable to retrieve starting timestamp from Prometheus!"
    echo "Prometheus snapshot started" 1>&2
}

function retrieve_prometheus_snapshot() {
    [[ -n "$prometheus_snapshot_start_ts" ]] || return
    echo "Retrieving Prometheus snapshot" 1>&2
    sleep 60
    local prometheus_snapshot_end_ts
    prometheus_snapshot_end_ts=$(retrieve_prometheus_timestamp)
    local promdb_name="promdb_${prometheus_snapshot_start_ts}_${prometheus_snapshot_end_ts}"
    local promdb_path="${artifactdir:+${artifactdir}/}${promdb_name}.tar"
    if "${OC}" exec -n openshift-monitoring prometheus-k8s-0 -c prometheus -- /bin/sh -c "tar cf - . -C /prometheus --transform 's,^[.],./${promdb_name},' .; true" > "$promdb_path" ; then
	echo "Prometheus snapshot retrieved" 1>&2
    else
	echo "Unable to retrieve Prometheus snapshot" 1>&2
    fi
}

function finis() {
    if [[ -n "$*" ]] ; then
	echo "$*" 1>&2
    fi
    if [[ "$monitor_pid" -ne 0 ]] ; then
	exec 3>&2 2>/dev/null
	kill -TERM "$monitor_pid"
	wait "$monitor_pid"
	exec 2>&3 3>&-
	monitor_pid=
    fi
    if [[ -n "$job_pid" ]] ; then
	exec 3>&2 2>/dev/null
	kill -TERM "$job_pid"
	wait "$job_pid"
	exec 2>&3 3>&-
	job_pid=
    fi
    local saved_starting_timestamp=$starting_timestamp
    local ending_timestamp
    local status
    if [[ -n "${starting_timestamp:-}" && $$ -eq "$BASHPID" ]] ; then
	local ending_timestamp
	ending_timestamp=$(date +%s)
	local statusmsg=Passed

	if [[ -n "${jobs[*]}" ]] ; then
	    echo "Run times:"
	    local job
	    for job in "${jobs[@]}" ; do
		printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	    done
	fi
	if [[ -n "${failures[*]}" ]] ; then
	    echo "Failing jobs:"
	    for job in "${failures[@]}" ; do
		printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	    done
	    fail=1
	fi

	if ((interrupted)) ; then
	    status=INCOMPLETE
	    statusmsg=Interrupted
	elif ((timedout)) ; then
	    status=TIMEDOUT
	    statusmsg='Timed out'
	elif ((fail)) ; then
	    status=FAIL
	    statusmsg=Failed
	else
	    status=PASS
	fi
	if [[ -n "$prometheus_snapshot_start_ts" ]] ; then
	    retrieve_prometheus_snapshot
	fi
	echo "Run took $(to_hms "$starting_timestamp" "$ending_timestamp") ($statusmsg)"
	starting_timestamp=
	if [[ -n "$artifactdir" && -d "$artifactdir" ]] ; then
	    cat > "$artifactdir/clusterbuster-ci-results.json" <<EOF
{
  "result": "$status",
  "job_start": "$(date -Is -u --date="@$saved_starting_timestamp")",
  "job_end": "$(date -Is -u --date="@$ending_timestamp")",
  "job_runtime": $((ending_timestamp - saved_starting_timestamp)),
  "ran": [
$(report_results "${jobs[@]}")
  ],
  "failed": [
$(report_results "${failures[@]}")
  ]
}
EOF
	fi

	if [[ -n "$analyze_results" ]] ; then
	    "$__analyze__" ${analysis_format:-r "$analysis_format"} -o "$analyze_results" "$artifactdir"
	fi
	if [[ -n "$python_venv" && -d "$python_venv" ]] ; then
	    if type -t deactivate >/dev/null ; then
		# Some versions of python venv assume that $1 works correctly;
		# ensure that those don't break.
		if ((set_u_works)) ; then set +u; fi
		deactivate
		if ((set_u_works)) ; then set -u; fi
	    fi
	    rm -rf "$python_venv"
	fi
    fi
    exit $fail
}

function warn() {
    echo "$*" 1>&2
}

function fatal() {
    fail=1
    finis "$*"
}

function parse_time() {
    local time=$1
    # shellcheck disable=SC2206
    local -a times=(${time//:/ })
    local -i d=0
    local -i h=0
    local -i m=0
    local -i s=0
    case "${#times[@]}" in
	1)
	    s=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	2)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	3)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	4)
	    d=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    h=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[3]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	*)
	    fatal "Malformed time $time"
	    ;;
    esac
    echo "$(( (d * 86400) + (h * 3600) + (m * 60) + s ))"
}

function splitarg() {
    echo "${*//,/ }"
}

function set_pin_nodes() {
    if [[ -z "$client_pin_node" || -z "$server_pin_node" || -z "$sync_pin_node" ]] ; then
	local -a nodes
	# shellcheck disable=SC2207
	nodes=($("${OC}" get node -l node-role.kubernetes.io/worker= -o jsonpath='{.items[*].metadata.name}'))
	local -i node_count=${#nodes[@]}
	if ((node_count < 1)) ; then
	    finis "No nodes found!"
	fi
	if [[ -z "$client_pin_node" ]] ; then
	    client_pin_node=${nodes[$((0 % node_count))]}
	fi
	if [[ -z "$server_pin_node" ]] ; then
	    server_pin_node=${nodes[$((1 % node_count))]}
	fi
	if [[ -z "$sync_pin_node" ]] ; then
	    sync_pin_node=${nodes[$((2 % node_count))]}
	fi
    fi
}

function get_node_memory() {
    local node=$1
    local mem
    mem=$("${OC}" get node "$node" -ojsonpath='{.status.allocatable.memory}')
    parse_size "$mem"
}

function list_profiles() {
    local prefix=${1:-}
    function list_profiles_1() {
	shopt -s nullglob
	for f in "${__profiledir__}"/*.profile ; do
	    f=${f%%.profile}
	    f=${f##*/}
	    echo "$f"
	done
    }
    while read -r profile ; do
	echo "$prefix$profile"
    done <<< "$(list_profiles_1)"
}

function process_profile() {
    local profile=$1
    if [[ -f "${__profiledir__}/${profile}.profile" ]] ; then
	local line=
	while IFS= read -r line ; do
	    line=${line%%#*}
	    line=${line## }
	    line=${line##	}
	    if [[ -z "$line" ]] ; then continue; fi
	    process_option "$line"
	done < "${__profiledir__}/${profile}.profile"
    else
	fatal "Cannot find profile $profile in $__profiledir__"
    fi
}

function force_pull_base_image() {
    for n in $("${OC}" get node --no-headers |awk '{print $1}') ; do
	if ((debugonly)) ; then
	    echo "${OC}" debug --no-stdin=true --no-tty=true node/"$n" -- chroot /host sh -c ' podman pull quay.io/rkrawitz/bench-army-base; podman pull quay.io/rkrawitz/bench-army-base'
	else
	    "${OC}" debug --no-stdin=true --no-tty=true node/"$n" -- chroot /host sh -c ' podman pull quay.io/rkrawitz/bench-army-base; podman pull quay.io/rkrawitz/bench-army-base' &
	fi
    done
    if ((! debugonly)) ; then
	wait
    fi
}

function monitor_1() {
    local timeout=${1:-$run_timeout}
    if ((timeout <= 0)) ; then
	timeout=infinity
    fi
    # Allow the main process to catch these signals and terminate us.
    # However, allow SIGHUP through so that if we get hung up on we'll
    # safely exit.
    sleep "$timeout" &
    local sleep_pid=$!
    trap "if [[ -n '$sleep_pid' ]] ; then kill '$sleep_pid'; fi; exit" TERM INT
    wait "$sleep_pid"
    kill -USR1 $$
}

function monitor() {
    (monitor_1 "$@") &
    monitor_pid=$!
}

function help() {
    ${PAGER:-less} <<EOF
Usage: $0 [options] [workloads]
    Here is a brief description of all available workloads.  If not provided, 
        all workloads are run:
$(_document_workloads)

    Size options may be specified by bytes, or K, Ki, M, Mi, G, Gi, T, or Ti.
    Boolean options may be specified as 1, yes, or true, with anything else
        equivalent to false.

    General options:

        --client-pin-node=node  Pin client pods to the specified node.
                                If not provided, the first worker node
                                (in the order returned by 'oc get nodes')
                                is used.
        --server-pin-node=node  Pin server pods to the specified node.
                                By default, the second worker node is used.
        --sync-pin-node=node    Pin the sync pod to the specified node.
                                By default, the third worker node is used.
        --pin-node[=class]=node
                                Pin pods of the specified class to the 
                                specified node.  Class is optional; if
                                specified, it should be either client,
                                server, or pin.
        --runtime=seconds       Run the job for the given number of seconds,
                                if applicable (this does not apply to the
                                files test).  May be overridden by
                                workload-specific values.
        --timeout=seconds       Time the job out after the given number of
                                seconds.  May be overridden by
                                workload-specific values.
        --artifactdir=dir       Store all run artifacts in the specified
                                directory.  Individual runs are in
                                subdirectories.
        --reportformat=format   Format of report printed during run.
                                Default none.  Options are as in clusterbuster.
        --analysisformat=format Format of post-run analysis.  Currently 'ci'
                                and 'summary' are supported.
        --runtimeclasses=classes
                                Comma-separated list of runtime classes to test.
                                Default is <empty> (i. e. default) and kata.
        --reportobjectcreation  Whether to report object creation.
        --cleanup               Clean up all pods after last run.
        --restart               Restart any failed or incomplete jobs from a
                                prior run.  Default is no.  Can only be used
                                with identical parameters to previous run.
        --profile=profile       Which profile to use.  Default is no profile.
                                Known profiles:
$(list_profiles '                                - ')
        --uuid=uuid             Specify a uuid for the job run.  Default is to
                                generate one.
        --prometheus-snapshot
                                Take a Prometheus snapshot and save to the
                                artifacts directory

    Virtiofsd configuration options (for kata):
        --virtiofsd-direct      Allow direct I/O requests from guest to operate
                                as such.  Default is yes (NOT the kata default)
        --virtiofsd-writeback   Use write back caching for virtiofsd.  Default
                                is no.
        --virtiofsd-threadpoolsize=n
                                Use the specified thread pool size for
                                virtiofsd.  Default is unset (equivalent to 1).

    Workload-specific options:
$(_help_options_workloads)

EOF
    exit
}

function set_pin_node() {
    local setting="${1:-}"
    if [[ $setting = *'='* ]] ; then
	local -a vals=(${setting/=/ })
	case "${vals[0]}" in
	    server) server_pin_node="${vals[1]}" ;;
	    client) client_pin_node="${vals[1]}" ;;
	    sync  ) sync_pin_node="${vals[1]}"   ;;
	    *)					 ;;
	esac
    elif [[ -n "$setting" ]] ; then
	server_pin_node=$setting
	client_pin_node=$setting
	sync_pin_node=$setting
    fi
}

function process_option() {
    local option=$1
    local noptname
    local noptname1
    local optvalue
    read -r noptname1 noptname optvalue <<< "$(parse_option "$option")"
    optvalue=$(splitarg "$optvalue")
    # shellcheck disable=SC2206
    case "$noptname1" in
	help*) help									;;
	debug*) debugonly="$(bool "$optvalue")"						;;

	clientpin*) client_pin_node=$optvalue						;;
	serverpin*) server_pin_node=$optvalue						;;
	syncpin*) sync_pin_node=$optvalue						;;
	pin*) set_pin_node "$optvalue"							;;
	jobruntime|runtime) job_runtime=$optvalue					;;
	jobtimeout|timeout) job_timeout=$optvalue					;;
	artifactdir) artifactdir="${optvalue:-${artifactdir:-$(pwd)}}"			;;
	analyze*) analyze_results="$optvalue"						;;
	reportformat*) report_format=$optvalue						;;
	analysisformat*) analysis_format=$optvalue					;;
	runtimeclass*) readarray -t runtimeclasses <<< "$optvalue"			;;
	reportobject*) report_object_creation=$(bool "$optvalue")			;;
	cleanup*) cleanup=$(bool "$optvalue")						;;
	restart) restart=$(bool "$optvalue")						;;
	runtimeout) run_timeout=$(parse_time "$optvalue")				;;
	profile|runtype) process_profile "$optvalue"					;;
	forcepull*) force_pull_image="$(bool "$optvalue")"				;;
	usepythonvenv*) use_python_venv="$(bool "$optvalue")"				;;
	basename) basename=$optvalue							;;
	uuid) uuid=$optvalue								;;
	forcecleanupiknowthisisdangerous) force_cleanup_timeout=$optvalue		;;
	prometheussnapshot) take_prometheus_snapshot=$(bool "$optvalue")		;;

	virtiofsdwriteback) virtiofsd_writeback=$(bool "$optvalue")			;;
	virtiofsddirect) virtiofsd_direct=$(bool "$optvalue")				;;
	virtiofsdthreadpool) virtiofsd_threadpoolsize=$optvalue				;;

	# Unknown option -- can we delegate?
	*)
	    if ! call_api -A -a process_option "$option" ; then
		unknown_opts+=("$option")
		unknown_opt_names+=("$noptname ($noptname1)")
	    fi
	    ;;
    esac
}

if [[ -z "$OC" ]] ; then
    fatal "Cannot find oc or kubectl"
fi

while getopts 'hn-:B:' opt ; do
    case "$opt" in
	-) process_option "$OPTARG"	;;
	h) help				;;
	n) dontdoit=-n			;;
	B) basename=$OPTARG		;;
	*)				;;
    esac
done

if [[ -n "${unknown_opt_names[*]}" ]] ; then
    help "${unknown_opt_names[@]}"
fi

shift $((OPTIND - 1))
if [[ -n "$*" ]] ; then
    workloads=("$@")
fi

function compute_timeout() {
    local -i timeout=$1
    ((timeout <= 0)) && timeout=$job_timeout
    ((timeout < 0)) && timeout=$((-timeout))
    echo "$timeout"
}

if [[ -z "$artifactdir" && $analyze_results -ne 0 ]] ; then
    fatal "--analyze-results may only used with --artifactdir set"
fi

set_pin_nodes

function computeit() {
    bc <<< "$1" | sed -e 's/\..*$//'
}

function python_create_venv() {
    local dir=$1
    if ((debugonly)) ; then
	echo "Create venv"
    else
	python3 -m venv "$dir" || fatal "Can't create venv!"
	# Some versions of venv generate activate/deactivate scripts
	# that do not protect access to potentially unbound variables.
	if ((set_u_works)) ; then set +u; fi
	# shellcheck disable=SC1091
	. "$1/bin/activate" || fatal "Can't activate venv!"
	if ((set_u_works)) ; then set -u; fi
	python3 -m pip -q install --upgrade pip || fatal "Can't upgrade pip!"
	pip3 -q install prometheus-api-client==0.5.0 openshift-client==1.0.14 Jinja2==3.0.1 || fatal "Can't install Python packages!"
    fi
}

function to_hms() {
    local -i start=$1
    local -i end=$2
    local -i interval=$((end-start))

    local -i h=$((interval / 3600))
    local -i m=$(((interval % 3600) / 60))
    local -i s=$((interval % 60))
    if ((h > 0)) ; then
	printf "%d:%02d:%02d\n" "$h" "$m" "$s"
    else
	printf "%d:%02d\n" "$m" "$s"
    fi
}

function xruntimeclass() {
    local runtimeclass=$1
    if [[ $runtimeclass == kata ]] ; then
	echo kata
    else
	echo runc
    fi
}

function doit() {
    echo "$*"
    if ((! debugonly)) ; then
	exec "$@" &
	job_pid=$!
	wait "$job_pid"
	local status=$?
	job_pid=
	return $status
    fi
}

function run_clusterbuster() {
    local OPTIND=0
    local opt
    local -i error_is_failure=1
    local jobdir=
    local tmp_jobdir=
    local jobname=
    local runtimeclass=
    local workload=
    local timeout=
    local job_runtime
    while getopts 'ynj:r:R:w:t:' opt "$@" ; do
	case "$opt" in
	    y) error_is_failure=0	;;
	    n) error_is_failure=1	;;
	    j) jobname="$OPTARG"	;;
	    r) runtimeclass="$OPTARG"	;;
	    R) job_runtime="$OPTARG"	;;
	    w) workload="$OPTARG"	;;
	    t) timeout="$OPTARG"	;;
	    *)				;;
	esac
    done
    [[ -z "$jobname" ]] && fatal "Job name must be specified"
    [[ -z "$workload" ]] && fatal "Workload must be specified"
    jobname=$(printf '%s-%s-%04d-%s' "$workload" "$(xruntimeclass "$runtimeclass")" "$counter" "$jobname")
    jobdir=${artifactdir:+$artifactdir/$jobname}
    counter=$((counter+1))
    if [[ $debugonly -eq 0 && -n "$jobdir" && -d "$jobdir" && -f "$jobdir/clusterbuster-report.json" ]] ; then
	if ((restart)) ; then
	    echo "$jobname is already present"
	    return 0
	else
	    rm -rf "$jobdir"
	fi
    fi
    tmp_jobdir="${jobdir:+${jobdir}.tmp}"

    shift $((OPTIND-1))
    local -i status=0
    local -i job_start
    local -i job_end
    job_start=$(date +%s)
    echo
    echo "*** Running $jobname at $(date -Is -u)"
    # shellcheck disable=SC2090
    doit "$__clusterbuster__" ${dontdoit:+"$dontdoit"} \
	 ${basename:+"--basename=$basename"} --uuid="$uuid" \
	 --precleanup --cleanup="$cleanup" --image-pull-policy=IfNotPresent \
	 --metrics --report="$report_format" --workload="$workload" \
	 ${job_runtime:+"--workload_runtime=$job_runtime"} \
	 ${client_pin_node:+"--pin-node=client=$client_pin_node"} \
	 ${server_pin_node:+"--pin-node=server=$server_pin_node"} \
	 ${sync_pin_node:+"--pin-node=sync=$sync_pin_node"} \
	 ${timeout:+"--timeout=$timeout"} \
	 ${jobname:+"--jobname=$jobname"} \
	 ${tmp_jobdir:+"--artifactdir=$tmp_jobdir"} \
	 ${runtimeclass:+"--runtimeclass=$runtimeclass"} \
	 --virtiofsd_direct="$virtiofsd_direct" \
	 --virtiofsd_writeback="$virtiofsd_writeback" \
	 --virtiofsd_threadpoolsize="$virtiofsd_threadpoolsize" \
	 --report_object_creation="$report_object_creation" \
	 ${force_cleanup_timeout:+"--force-cleanup-i-know-this-is-dangerous=$force_cleanup_timeout"} \
	 "$@" 2>&1 || status=$?
    if ((! debugonly)) ; then
	job_end=$(date +%s)
	job_runtime="$(to_hms "$job_start" "$job_end")"
	echo "Job took $job_runtime, done at $(date -Is -u)"
	job_runtimes[$jobname]="$job_runtime"
	if ((status == 0)) ; then
	    jobs+=("$jobname")
	    if [[ -n "$jobdir" ]] ; then
		[[ -d "$jobdir" ]] && fatal "$jobdir exists (shouldn't!)"
		mv "$tmp_jobdir" "$jobdir" || fatal "Can't rename $tmp_jobdir to $jobdir"
	    fi
	else
	    ((error_is_failure)) && failures+=("$jobname")
	    if [[ -n "$jobdir" ]] ; then
		local fail_jobdir_base="${jobdir}.FAIL"
		local fail_jobdir=$fail_jobdir_base
		local -i jobdir_idx=1
		while [[ -d "$fail_jobdir" ]] ; do
		    fail_jobdir="${fail_jobdir_base}.$jobdir_idx"
		    jobdir_idx=$((jobdir_idx+1))
		done
		mv "$tmp_jobdir" "$fail_jobdir" || fatal "Can't rename $tmp_jobdir to $fail_jobdir"
	    fi
	    ((hard_fail_on_error)) && finis "Job $jobname failed, exiting!"
	fi
    fi
    return $status
}

if [[ -z "${workloads[*]}" ]] ; then
    workloads=($(print_workloads))
fi

bad_workload=0
for workload in "${workloads[@]}" ; do
    if ! get_workload "$workload" >/dev/null 2>&1; then
	bad_workload=1
	echo "Unsupported workload $workload" 1>&2
    fi
done
if ((bad_workload)) ; then
    exit 1
fi

if ((! debugonly)) ; then
    set_pin_nodes
    if ((take_prometheus_snapshot)) ; then
	start_prometheus_snapshot
    fi
    starting_timestamp=$(date +%s)
    job_datestamp=$(date -u '+%Y_%m_%dT%H_%M_%S%z' --date=@"$starting_timestamp")
    artifactdir=${artifactdir//%s/$job_datestamp}
    if ((restart)) ; then
	if [[ -d "$artifactdir" ]] ; then
	    for d in "$artifactdir"/* ; do
		if [[ -d "$d" && -f "$d/clusterbuster-report.json" ]] ; then
		    uuid=$(jq -r .metadata.uuid "$d/clusterbuster-report.json")
		    break
		fi
	    done
	fi
    else
	if [[ -n "$artifactdir" && -f "$artifactdir/clusterbuster-report.json" ]] ; then
	    rm -rf "$artifactdir"
	fi
	if [[ ! -d "$artifactdir" ]] ; then
	    mkdir -p "$artifactdir" || fatal "Cannot create artifact directory!"
	fi
    fi
    exec > >(tee -a "$artifactdir/stdout.kata-perf-suite.log")
    exec 2> >(tee -a "$artifactdir/stderr.kata-perf-suite.log" >&2)

    if ((use_python_venv)) ; then
	python_venv=$(mktemp -d -t "cb-ci-venv.XXXXXXXX")
	python_create_venv "$python_venv"
    fi

    monitor "$run_timeout"
    trap 'if ((monitor_pid > 0)) ; then kill -9 "$monitor_pid"; monitor_pid=0; fi; timedout=1; if ((job_pid > 0)) ; then kill -TERM "$job_pid"; echo Cleaning up 1>&2 ; fi; fail=3; finis "Run timed out after $run_timeout seconds"' USR1
    trap 'if ((monitor_pid > 0)) ; then kill -9 "$monitor_pid"; monitor_pid=0; fi; interrupted=1; if ((job_pid > 0)) ; then kill -TERM "$job_pid"; echo Cleaning up 1>&2; fi; if ((fail < 2)); then fail=2; fi; finis "Run interrupted"' TERM INT HUP
    trap 'finis' EXIT
    if ((force_pull_image)) ; then
	force_pull_base_image
    fi
fi

for runtimeclass in "${runtimeclasses[@]}" ; do
    for workload in "${workloads[@]}" ; do
	# Use a separate counter for each workload/runtime
	counter=0
	call_api -w "$workload" test "$runtimeclass" "$job_runtime"
    done
done
