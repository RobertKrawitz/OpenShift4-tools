#!/bin/bash

# Copyright 2022 Robert Krawitz/Red Hat
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

declare -i set_u_works=1
if (( BASH_VERSINFO[0] >= 5 || (BASH_VERSINFO[0] == 4 && BASH_VERSINFO[1] >= 4) )) ; then
    set -u
else
    set_u_works=0
    cat 1>&2 <<EOF
Warning: bash version at least 4.4 is recommended for using ${0##*/}.
Actual version is ${BASH_VERSION}
EOF
fi

declare OC=${OC:-${KUBECTL:-}}
OC=${OC:-$(type -p oc)}
OC=${OC:-$(type -p kubectl)}	# kubectl might not work, though...
declare __topdir__
__topdir__="$(realpath "$(dirname "$(realpath -e "$0")")/..")"
declare __libdir__="${__topdir__}/lib/clusterbuster"
declare __clusterbuster__="${__topdir__}/clusterbuster"
declare __force_pull_clusterbuster_image__="${__topdir__}/force-pull-clusterbuster-image"
declare __analyze__="${__topdir__}/analyze-clusterbuster-report"
declare __profiledir__="${__libdir__}/CI/profiles"
declare __workloaddir__="${__libdir__}/CI/workloads"

[[ -d "$__libdir__" ]] || fatal "Can't find my library dir!"

. "${__libdir__}"/libclusterbuster.sh
load_workloads -s ".ci" "$__libdir__" CI

declare client_pin_node=
declare server_pin_node=
declare sync_pin_node=
declare -i job_runtime=120
declare -i job_timeout=-1200
declare artifactdir=
declare report_format=none
declare analysis_format=
declare dontdoit=
declare -i run_timeout=0
declare -i monitor_pid=0
declare -i force_pull_image=0
declare job_pid=
declare -i use_python_venv=1
declare python_venv=
declare analyze_results=
declare -i debugonly=0
declare force_cleanup_timeout=
declare -i take_prometheus_snapshot=0
declare unique_job_prefix=
declare snapshot_date_format='%Y_%m_%dT%H_%M_%S%z'
declare prometheus_snapshot_start_ts=
declare job_delay=0
declare -i pin_jobs=1
declare -a workloads=()
declare -a debugargs=()
declare extra_args=()

declare -a runtimeclasses=('' 'kata' 'vm')
declare -a extra_clusterbuster_args=()
declare -A known_clusterbuster_options=()

declare -i fail=0
declare -i interrupted=0
declare -i timedout=0
declare -i counter=0
declare -i hard_fail_on_error=0
declare -i restart=0
declare -i started_prom_capture=0
# shellcheck disable=2155
declare uuid=$(uuidgen -r)

declare -a failures=()
declare -a jobs=()
declare -A job_runtimes=()
declare -A runtimeclass_ok=()
declare prerun=
declare postrun=

declare starting_timestamp=
declare job_datestamp

function report_results() {
    if [[ -n "$*" ]] ; then
	local -a results=("${@/#/    \"}")
	results=("${results[@]/%/\"}")
	local result
	result="$(IFS=","; echo "${results[*]}")"
	echo "${result//,/,$'\n'}"
    fi
}

function retrieve_prometheus_timestamp() {
    "${OC}" exec -n openshift-monitoring prometheus-k8s-0 -- /bin/sh -c "date -u '+$snapshot_date_format'"
}

function start_prometheus_snapshot() {
    echo "Starting Prometheus snapshot" 1>&2
    "${OC}" delete pod -n openshift-monitoring prometheus-k8s-0
    local -i retry=12
    until "${OC}" get pod -n openshift-monitoring prometheus-k8s-0 >/dev/null 2>&1 ; do
	echo "Promtheus pod did not start, $retry attempt(s) left" 1>&2
	((retry > 0)) || fatal "Prometheus pod did not restart!"
	retry=$((retry-1))
	sleep 5
    done
    "${OC}" wait --for=condition=Ready -n openshift-monitoring pod/prometheus-k8s-0 || fatal "Prometheus pod did not become ready"
    # Wait for prometheus pod to fully initialize
    sleep 60
    prometheus_snapshot_start_ts=$(retrieve_prometheus_timestamp) || fatal "Unable to retrieve starting timestamp from Prometheus!"
    echo "Prometheus snapshot started" 1>&2
}

function retrieve_prometheus_snapshot() {
    [[ -n "$prometheus_snapshot_start_ts" ]] || return
    echo "Retrieving Prometheus snapshot" 1>&2
    sleep 60
    local prometheus_snapshot_end_ts
    prometheus_snapshot_end_ts=$(retrieve_prometheus_timestamp)
    local promdb_name="promdb_${prometheus_snapshot_start_ts}_${prometheus_snapshot_end_ts}"
    local promdb_path="${artifactdir:+${artifactdir}/}${promdb_name}.tar"
    if "${OC}" exec -n openshift-monitoring prometheus-k8s-0 -c prometheus -- /bin/sh -c "tar cf - . -C /prometheus --transform 's,^[.],./${promdb_name},' .; true" > "$promdb_path" ; then
	echo "Prometheus snapshot retrieved" 1>&2
    else
	echo "Unable to retrieve Prometheus snapshot" 1>&2
    fi
}

function _report_ci_results() {
    local status=$1
    local start_timestamp=$2
    local end_timestamp=$3
    cat > "$artifactdir/clusterbuster-ci-results.json.tmp" <<EOF
{
  "result": "$status",
  "job_start": "$(date -Is -u --date="@$start_timestamp")",
  "job_end": "$(date -Is -u --date="@$end_timestamp")",
  "job_runtime": $((end_timestamp - start_timestamp)),
  "ran": [
$(report_results "${jobs[@]}")
  ],
  "failed": [
$(report_results "${failures[@]}")
  ]
}
EOF
}

function report_ci_results() {
    if [[ -z "${artifactdir:-}" || ! -d "$artifactdir" ]] ; then
	return
    fi
    local OPTIND=0
    local OPTARG
    local status=
    local -i start_timestamp=${starting_timestamp:-0}
    local -i end_timestamp=-1
    while getopts 'e:s:t:' opt "$@" ; do
	case "$opt" in
	    s) status=$OPTARG 		;;
	    t) start_timestamp=$OPTARG	;;
	    e) end_timestamp=$OPTARG	;;
	    *)				;;
	esac
    done
    if ((end_timestamp < 0)) ; then
	end_timestamp=$(date +%s)
    fi
    if [[ -z "$status" ]] ; then
	if [[ -n "${failures[*]}" ]] ; then
	    status=FAILING
	else
	    status=PASSING
	fi
    fi
    _report_ci_results "$status" "$start_timestamp" "$end_timestamp" &&
	mv "$artifactdir/clusterbuster-ci-results.json.tmp" "$artifactdir/clusterbuster-ci-results.json"
}

function finis() {
    if [[ -n "$*" ]] ; then
	echo "$*" 1>&2
    fi
    if [[ "$monitor_pid" -ne 0 ]] ; then
	exec 3>&2 2>/dev/null
	kill -TERM "$monitor_pid"
	wait "$monitor_pid"
	exec 2>&3 3>&-
	monitor_pid=
    fi
    if [[ -n "$job_pid" ]] ; then
	exec 3>&2 2>/dev/null
	kill -TERM "$job_pid"
	wait "$job_pid"
	exec 2>&3 3>&-
	job_pid=
    fi
    local saved_starting_timestamp=$starting_timestamp
    local status
    if [[ -n "${starting_timestamp:-}" && $$ -eq "$BASHPID" ]] ; then
	local ending_timestamp
	ending_timestamp=$(date +%s)
	local statusmsg=Passed

	if [[ -n "${jobs[*]}" ]] ; then
	    echo "Run times:"
	    local job
	    for job in "${jobs[@]}" ; do
		printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	    done
	else
	    fail=1
	fi
	if [[ -n "${failures[*]}" ]] ; then
	    echo "Failing jobs:"
	    for job in "${failures[@]}" ; do
		printf "%10s %s\n" "${job_runtimes[$job]}" "$job"
	    done
	    fail=1
	fi

	if ((interrupted)) ; then
	    status=INCOMPLETE
	    statusmsg=Interrupted
	elif ((timedout)) ; then
	    status=TIMEDOUT
	    statusmsg='Timed out'
	elif ((fail)) ; then
	    status=FAIL
	    statusmsg=Failed
	else
	    status=PASS
	fi
	if [[ -n "$prometheus_snapshot_start_ts" && $started_prom_capture -eq 0 ]] ; then
	    started_prom_capture=1
	    retrieve_prometheus_snapshot
	fi
	echo "Run took $(to_hms "$starting_timestamp" "$ending_timestamp") ($statusmsg)"
	starting_timestamp=
	report_ci_results -s "$status" -t "$saved_starting_timestamp" -e "$ending_timestamp"
	if [[ -n "$analyze_results" ]] ; then
	    # shellcheck disable=SC2086
	    local workload_pattern
	    workload_pattern="($(IFS='|'; echo "${workloads[*]}"))"
	    local -a analysis_classes=()
	    local runtimeclass
	    for runtimeclass in "${runtimeclasses[@]}" ; do
		analysis_classes+=("$artifactdir:name=${runtimeclass:-runc}:job_pattern=^$workload_pattern-${runtimeclass:-runc}-[0-9]{4,}")
	    done
	    "$__analyze__" ${analysis_format:+-r "$analysis_format"} -o "$analyze_results" "${analysis_classes[@]}"
	fi
	if [[ -n "$python_venv" && -d "$python_venv" ]] ; then
	    if type -t deactivate >/dev/null ; then
		# Some versions of python venv assume that $1 works correctly;
		# ensure that those don't break.
		if ((set_u_works)) ; then set +u; fi
		deactivate
		if ((set_u_works)) ; then set -u; fi
	    fi
	    rm -rf "$python_venv"
	fi
    fi
    exit $fail
}

function warn() {
    echo "$*" 1>&2
}

function fatal() {
    fail=1
    finis "$*"
}

function parse_time() {
    local time=$1
    # shellcheck disable=SC2206
    local -a times=(${time//:/ })
    local -i d=0
    local -i h=0
    local -i m=0
    local -i s=0
    case "${#times[@]}" in
	1)
	    s=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	2)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	3)
	    h=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	4)
	    d=$(echo "${times[0]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    h=$(echo "${times[1]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    m=$(echo "${times[2]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    s=$(echo "${times[3]}" | sed -e 's/^0*//' -e 's/^$/0/')
	    ;;
	*)
	    fatal "Malformed time $time"
	    ;;
    esac
    echo "$(( (d * 86400) + (h * 3600) + (m * 60) + s ))"
}

function splitarg() {
    echo "${*//,/ }"
}

function get_available_nodes() {
    local -a nodes
    local role
    if ((debugonly)) ; then
	echo node1 node2 node3
    else
	for role in 'node-role.kubernetes.io/clusterbuster=' 'node-role.kubernetes.io/worker=,node-role.kubernetes.io/master!=,node-role.kubernetes.io/infra!=' 'node-role.kubernetes.io/worker=' ; do
	    readarray -d ' ' -t nodes < <("${OC}" get node -l "$role" -o jsonpath='{.items[*].metadata.name}')
	    if ((${#nodes[@]} >= 1)) ; then
		echo "${nodes[*]}"
		return
	    fi
	done
    fi
    (IFS=$'\n'; echo "${nodes[*]}")
}

function set_pin_nodes() {
    if ((! pin_jobs)) ; then return; fi
    if [[ -z "$client_pin_node" || -z "$server_pin_node" || -z "$sync_pin_node" ]] ; then
	local -a nodes
	readarray -d ' ' -t nodes <<< "$(get_available_nodes)"
	nodes=("${nodes[@]//$'\n'/}")
	local -i node_count=${#nodes[@]}
	if ((node_count < 1)) ; then
	    finis "No nodes found!"
	fi
	if [[ -z "$client_pin_node" ]] ; then
	    client_pin_node=${nodes[$((0 % node_count))]}
	fi
	if [[ -z "$server_pin_node" ]] ; then
	    server_pin_node=${nodes[$((1 % node_count))]}
	fi
	if [[ -z "$sync_pin_node" ]] ; then
	    sync_pin_node=${nodes[$((2 % node_count))]}
	fi
    fi
}

function get_node_memory() {
    local node=$1
    if ((debugonly)) ; then
	echo "$((32 * 1024 * 1024 * 1024))"
    else
	local mem
	mem=$("${OC}" get node "$node" -ojsonpath='{.status.allocatable.memory}')
	parse_size "$mem"
    fi
}

function list_profiles() {
    local prefix=${1:-}
    function list_profiles_1() {
	shopt -s nullglob
	for f in "${__profiledir__}"/*.profile ; do
	    f=${f%%.profile}
	    f=${f##*/}
	    echo "$f"
	done
    }
    while read -r profile ; do
	echo "$prefix$profile"
    done <<< "$(list_profiles_1)"
}

function process_profile() {
    local profile=$1
    local profile_in_dir=0
    if [[ $profile != *'/'* ]] ; then
	profile="${__profiledir__}/${profile}.profile"
	profile_in_dir=1
    fi
    if [[ -f "$profile" && -r "$profile" ]] ; then
	local line=
	while IFS= read -r line ; do
	    # shellcheck disable=SC1003
	    while [[ $line = *'\' ]] ; do
		line=${line::-1}
		local tline
		IFS= read -r tline
		[[ -z "$tline" ]] && break
		line+="$tline"
	    done
	    line=${line%%#*}
	    line=${line## }
	    line=${line##	}
	    if [[ -z "$line" ]] ; then continue; fi
	    process_option "$line"
	done < "$profile"
    elif ((profile_in_dir)) ; then
	fatal "Cannot find profile $profile in $__profiledir__"
    else
	fatal "Cannot find profile $profile"
    fi
}

function monitor_1() {
    local timeout=${1:-$run_timeout}
    if ((timeout <= 0)) ; then
	timeout=infinity
    fi
    # Allow the main process to catch these signals and terminate us.
    # However, allow SIGHUP through so that if we get hung up on we'll
    # safely exit.
    sleep "$timeout" &
    local sleep_pid=$!
    # shellcheck disable=SC2064
    trap "if [[ -n '$sleep_pid' ]] ; then kill '$sleep_pid'; fi; exit" TERM INT
    wait "$sleep_pid"
    kill -USR1 $$
}

function monitor() {
    (monitor_1 "$@") &
    monitor_pid=$!
}

function help() {
    ${PAGER:-less} <<EOF
Usage: $0 [options | clusterbuster_options] [workloads]
    Here is a brief description of all available workloads.  If not provided,
        all workloads are run:
$(_document_workloads)

    Size options may be specified by bytes, or K, Ki, M, Mi, G, Gi, T, or Ti.
    Boolean options may be specified as 1, yes, or true, with anything else
        equivalent to false.
    Additional arguments that are not recognized are passed through to
        clusterbuster.

    General options:

        --client-pin-node=node  Pin client pods to the specified node.
                                If not provided, the first worker node
                                (in the order returned by 'oc get nodes')
                                is used.
        --server-pin-node=node  Pin server pods to the specified node.
                                By default, the second worker node is used.
        --sync-pin-node=node    Pin the sync pod to the specified node.
                                By default, the third worker node is used.
        --pin-node[=class]=node
                                Pin pods of the specified class to the
                                specified node.  Class is optional; if
                                specified, it should be either client,
                                server, or pin.
        --no-pin-nodes          Do not pin jobs to nodes.
        --runtime=seconds       Run the job for the given number of seconds,
                                if applicable (this does not apply to the
                                files test).  May be overridden by
                                workload-specific values.
        --timeout=seconds       Time the job out after the given number of
                                seconds.  May be overridden by
                                workload-specific values.
        --artifactdir=dir       Store all run artifacts in the specified
                                directory.  Individual runs are in
                                subdirectories.
        --reportformat=format   Format of report printed during run.
                                Default none.  Options are as in clusterbuster.
        --analysisformat=format Format of post-run analysis.  Currently 'ci'
                                and 'summary' are supported.
        --runtimeclasses=classes
                                Comma-separated list of runtime classes to test.
                                Default is <empty> (i. e. default) and kata.
        --cleanup               Clean up all pods after last run.
        --job-delay=N           Delay N seconds between jobs (default $job_delay)
        --restart               Restart any failed or incomplete jobs from a
                                prior run.  Default is no.  Can only be used
                                with identical parameters to previous run.
        --profile=profile       Which profile to use.  Default is no profile.
                                Known profiles:
$(list_profiles '                                - ')
        --uuid=uuid             Specify a uuid for the job run.  Default is to
                                generate one.
        --prometheus-snapshot
                                Take a Prometheus snapshot and save to the
                                artifacts directory
        --unique-prefix         Prefix the pod names in each job with a
                                distinct string to aid in later identification.

    All other options listed below may be of the form
    --option:<workload>:<runtime>=value to specify that the value should apply
    only to a particular workload and runtimeclass.  Either workload or
    runtimeclass may be omitted or be of the form
    :workload
    :workload1,workload2 (list)
    :!workload (negation)

    Workload-specific options:
$(_help_options_workloads)

  Clusterbuster options:
$("$__clusterbuster__" --help-options)

EOF
    exit
}

function set_pin_node() {
    local setting="${1:-}"
    if [[ $setting = *'='* ]] ; then
	# shellcheck disable=SC2206
	local -a vals=(${setting/=/ })
	case "${vals[0]}" in
	    server) server_pin_node="${vals[1]}" ;;
	    client) client_pin_node="${vals[1]}" ;;
	    sync  ) sync_pin_node="${vals[1]}"   ;;
	    *)					 ;;
	esac
    elif [[ -n "$setting" ]] ; then
	server_pin_node=$setting
	client_pin_node=$setting
	sync_pin_node=$setting
    fi
}

function _check_ci_option() {
    local noptname=$1
    local workload=$2
    local runtime=$3
    if [[ $noptname = *':'* && (-n "$workload" || -n "$runtime") ]] ; then
	local optbase=
	local optworkload=
	local optruntime=
	# shellcheck disable=SC2034
	IFS=: read -r optbase optworkload optruntime <<< "$noptname"
	if [[ (-z "$workload" || -z "$optworkload" || $workload = "$optworkload") &&
		  (-z "$runtime" || -z "$optruntime" || $runtime = "$optruntime") ]] ; then
	    true
	elif [[ $optworkload = *'!'* || $optworkload = *','* ||
		    $optruntime = *'!'* || $optruntime = *','* ]] ; then
	    local -a optworkloads
	    local -a optruntimes
	    IFS=, read -ra optworkloads <<< "$optworkload"
	    IFS=, read -ra optruntimes <<< "$optruntime"
	    local item
	    if [[ -n "$workload" && -n "$optworkload" ]] ; then
		local found=0
		for item in "${optworkloads[@]}" ; do
		    if [[ $item = "$workload" ]] ; then
			found=1
			break
		    elif [[ $item = '!'* && ${item:1} = "$workload" ]] ; then
			return 1
		    fi
		done
		((found)) || return 1
	    fi
	    if [[ -n "$runtime" && -n "$optruntime" ]] ; then
		local found=0
		for item in "${optruntimes[@]}" ; do
		    [[ $item = "$runtime" || ($item = '!'* && ${item:1} != "$runtime") ]] && return 0
		done
		return 1
	    fi
	    return 0
	else
	    return 1
	fi
    fi
}

function parse_ci_option() {
    local option=$1
    local workload=${2:-}
    local runtime=${3:-}
    local noptname1 noptname optvalue
    read -r noptname1 noptname optvalue <<< "$(parse_option "$option")"
    if _check_ci_option "$noptname" "$workload" "$runtime" ; then
	echo "${noptname1/:*/} ${noptname/:*/} $optvalue"
	return 0
    else
	return 1
    fi
}

function test_parse() {
    function _test_parse() {
	if parse_ci_option "$@" >/dev/null ; then
	    echo "Y  $(parse_ci_option "$@")"
	else
	    echo "   $(parse_ci_option "$@")"
	fi
    }

    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files pod
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files kata
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files pod
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files kata
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio vm
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio pod
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio kata
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio vm
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio pod
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio kata
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker vm
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker pod
    _test_parse volume:files,fio:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker kata
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker vm
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker pod
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto cpusoaker kata
    _test_parse volume:files:!pod,!kata=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto
    _test_parse volume:files:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files
    _test_parse volume:files:vm,kata=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files:pod,kata=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files:!vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto files vm
    _test_parse volume:files:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio
    _test_parse volume:files,fio:vm=test-pvc:pvc:/var/tmp/clusterbuster:size=auto:inodes=auto fio vm
    _test_parse volume:files,fio:!vm=:emptydir:/var/tmp/clusterbuster:size=auto fio
}

function check_clusterbuster_option() {
    local option=$1
    option=${option//-/}
    option=${option//_/}
    if [[ -z "${known_clusterbuster_options[*]}" ]] ; then
	local arg
	while read -r arg ; do
	    known_clusterbuster_options[$arg]=1
	done <<< "$("$__clusterbuster__" -h 2>&1 |grep -oEe '^[ \t]*--[-_[:lower:]]+' |sed -e 's/[ \t]//g' -e 's/[-_]//g' |sort |uniq)"
    fi
    [[ -n "${known_clusterbuster_options[$option]:-}" ]]
}

function process_option() {
    local option=$1
    local noptname
    local noptname1
    local optvalue
    local workload
    # shellcheck disable=SC2034
    read -r noptname1 noptname optvalue <<< "$(parse_ci_option "$option")"
    optvalue=$(splitarg "$optvalue")
    case "$noptname1" in
	help*) help									;;
	debugonly*) debugonly="$(bool "$optvalue")"					;;
	debug) debugargs+=("--debug=$optvalue")						;;
	clientpin*) client_pin_node=$optvalue						;;
	serverpin*) server_pin_node=$optvalue						;;
	syncpin*) sync_pin_node=$optvalue						;;
	nopinnode) pin_jobs=0								;;
	pinnode*) pin_jobs=$(bool "$optvalue")						;;
	pin*) set_pin_node "$optvalue"							;;
	jobruntime|runtime) job_runtime=$optvalue					;;
	jobtimeout|timeout) job_timeout=$optvalue					;;
	artifactdir) artifactdir="${optvalue:-${artifactdir:-$(pwd)}}"			;;
	analyze*) analyze_results="$optvalue"						;;
	reportformat*) report_format=$optvalue						;;
	analysisformat*) analysis_format=$optvalue					;;
	runtimeclass*) readarray -t runtimeclasses <<< "$(parse_optvalues "$optvalue")"	;;
	restart) restart=$(bool "$optvalue")						;;
	runtimeout) run_timeout=$(parse_time "$optvalue")				;;
	profile|runtype) process_profile "$optvalue"					;;
	forcepull*) force_pull_image="$(bool "$optvalue")"				;;
	usepythonvenv*) use_python_venv="$(bool "$optvalue")"				;;
	uuid) uuid=$optvalue								;;
	forcecleanupiknowthisisdangerous) force_cleanup_timeout=$optvalue               ;;
	prometheussnapshot) take_prometheus_snapshot=$(bool "$optvalue")		;;
	uniqueprefix) unique_job_prefix=$(bool -Y "$optvalue")				;;
	jobdelay) job_delay=$optvalue							;;
	*) extra_args+=("$option")							;;
    esac
}

function process_workload_options() {
    local OPTIND=0
    local opt
    local OPTARG
    local workload=${1:-}
    local runtimeclass=${2:-}
    shift 2
    extra_clusterbuster_args=()
    call_api -s -w "$workload" initialize_options
    local option
    for option in "${extra_args[@]}" "$@" ; do
	local noptname
	local noptname1
	local optvalue
	local optworkload
	# shellcheck disable=SC2034
	read -r noptname1 noptname optvalue <<< "$(parse_ci_option "$option" "$workload" "$runtimeclass")"
	if [[ -n "$noptname1" ]] ; then
	    optvalue=$(splitarg "$optvalue")
	    if ! call_api -a -w "$workload" process_option "$option" &&
		    check_clusterbuster_option "$noptname1" ; then
		extra_clusterbuster_args+=("--$noptname=$optvalue")
	    fi
	fi
    done
}

if [[ -z "$OC" ]] ; then
    fatal "Cannot find oc or kubectl"
fi

while getopts 'hn-:B:' opt ; do
    case "$opt" in
	-) process_option "$OPTARG"	;;
	h) help				;;
	n) debugonly=1; dontdoit=-n	;;
	*)				;;
    esac
done

shift $((OPTIND - 1))
if [[ -n "$*" ]] ; then
    workloads=("$@")
fi

function compute_timeout() {
    local -i timeout=$1
    ((timeout <= 0)) && timeout=$job_timeout
    ((timeout < 0)) && timeout=$((-timeout))
    echo "$timeout"
}

if [[ -z "$artifactdir" && $analyze_results -ne 0 ]] ; then
    fatal "--analyze-results may only used with --artifactdir set"
fi

set_pin_nodes

function computeit() {
    bc <<< "$1" | sed -e 's/\..*$//'
}

function python_create_venv() {
    local dir=$1
    if ((debugonly)) ; then
	echo "Create venv"
    else
	python3 -m venv "$dir" || fatal "Can't create venv!"
	# Some versions of venv generate activate/deactivate scripts
	# that do not protect access to potentially unbound variables.
	if ((set_u_works)) ; then set +u; fi
	# shellcheck disable=SC1091
	. "$1/bin/activate" || fatal "Can't activate venv!"
	if ((set_u_works)) ; then set -u; fi
	python3 -m pip -q install --upgrade pip || fatal "Can't upgrade pip!"
	pip3 -q install prometheus-api-client==0.5.0 openshift-client==1.0.14 Jinja2==3.0.1 || fatal "Can't install Python packages!"
    fi
}

function to_hms() {
    local -i start=$1
    local -i end=$2
    local -i interval=$((end-start))

    local -i h=$((interval / 3600))
    local -i m=$(((interval % 3600) / 60))
    local -i s=$((interval % 60))
    if ((h > 0)) ; then
	printf "%d:%02d:%02d\n" "$h" "$m" "$s"
    else
	printf "%d:%02d\n" "$m" "$s"
    fi
}

function doit() {
    echo "${@@Q}"
    if ((! debugonly)) ; then
	exec "$@" &
	job_pid=$!
	wait "$job_pid"
	local status=$?
	job_pid=
	return $status
    fi
}

function check_runtimeclass() {
    function _check_runtimeclass() {
	if [[ $runtimeclass = vm ]] ; then
	    [[ -n "$(oc get hyperconverged --no-headers -A 2>/dev/null)" ]]
	else
	    oc get runtimeclass "$runtimeclass" >/dev/null 2>&1
	fi
    }
    local runtimeclass=${1:-runc}
    if [[ -z "${runtimeclass_ok[$runtimeclass]:-}" ]] ; then
	if [[ -z "$runtimeclass" || $runtimeclass = runc ]] || _check_runtimeclass "$runtimeclass" ; then
	    runtimeclass_ok[$runtimeclass]=1
	else
	    runtimeclass_ok[$runtimeclass]=0
	fi
    fi
    (( ${runtimeclass_ok[$runtimeclass]} ))
}

function run_clusterbuster_1() {
    local OPTIND=0
    local OPTARG
    local opt
    local -i error_is_failure=1
    local jobdir=
    local tmp_jobdir=
    local jobname=
    local runtimeclass=
    local workload=
    local timeout=
    local job_prefix=
    local job_runtime
    while getopts 'ynj:r:R:w:t:' opt "$@" ; do
	case "$opt" in
	    y) error_is_failure=0	;;
	    n) error_is_failure=1	;;
	    j) jobname="$OPTARG"	;;
	    r) runtimeclass="$OPTARG"	;;
	    R) job_runtime="$OPTARG"	;;
	    w) workload="$OPTARG"	;;
	    t) timeout="$OPTARG"	;;
	    *)				;;
	esac
    done
    [[ -z "$jobname" ]] && fatal "Job name must be specified"
    [[ -z "$workload" ]] && fatal "Workload must be specified"
    job_prefix=$(printf '%s-%s-%04d' "$workload" "${runtimeclass:-runc}" "$counter")
    jobname=$(printf '%s-%s-%04d-%s' "$workload" "${runtimeclass:-runc}" "$counter" "$jobname")
    jobdir=${artifactdir:+$artifactdir/$jobname}
    if [[ $debugonly -eq 0 && -n "$jobdir" && -d "$jobdir" && -f "$jobdir/clusterbuster-report.json" ]] ; then
	if ((restart)) ; then
	    echo "$jobname is already present"
	    return 0
	else
	    rm -rf "$jobdir"
	fi
    fi
    tmp_jobdir="${jobdir:+${jobdir}.tmp}"

    shift $((OPTIND-1))
    local -i status=0
    local -i job_start
    local -i job_end
    sleep "$job_delay"
    job_start=$(date +%s)
    echo
    echo "*** Running $jobname at $(date -Is -u)"
    # Runtime class needs to be after any deployment_type argument so
    # that VM will override.
    # shellcheck disable=SC2090
    doit "$__clusterbuster__" ${dontdoit:+"$dontdoit"} --uuid="$uuid" \
	 --precleanup --image-pull-policy=IfNotPresent \
	 --metrics --report="$report_format" --workload="$workload" \
	 "${debugargs[@]}" \
	 ${job_runtime:+"--workload_runtime=$job_runtime"} \
	 ${client_pin_node:+"--pin-node=client=$client_pin_node"} \
	 ${server_pin_node:+"--pin-node=server=$server_pin_node"} \
	 ${sync_pin_node:+"--pin-node=sync=$sync_pin_node"} \
	 ${timeout:+"--timeout=$timeout"} \
	 ${jobname:+"--jobname=$jobname"} \
	 ${tmp_jobdir:+"--artifactdir=$tmp_jobdir"} \
         ${force_cleanup_timeout:+"--force-cleanup-i-know-this-is-dangerous=$force_cleanup_timeout"} \
	 ${unique_job_prefix:+"--pod-prefix=$job_prefix"} \
	 "${extra_clusterbuster_args[@]}" \
	 ${runtimeclass:+"--runtimeclass=$runtimeclass"} \
	 "$@" 2>&1 || status=$?
    if ((! debugonly)) ; then
	job_end=$(date +%s)
	job_runtime="$(to_hms "$job_start" "$job_end")"
	echo "Job took $job_runtime, done at $(date -Is -u)"
	job_runtimes[$jobname]="$job_runtime"
	if ((status == 0)) ; then
	    jobs+=("$jobname")
	    if [[ -n "$jobdir" ]] ; then
		[[ -d "$jobdir" ]] && fatal "$jobdir exists (shouldn't!)"
		mv "$tmp_jobdir" "$jobdir" || fatal "Can't rename $tmp_jobdir to $jobdir"
	    fi
	else
	    ((error_is_failure)) && failures+=("$jobname")
	    if [[ -n "$jobdir" ]] ; then
		local fail_jobdir_base="${jobdir}.FAIL"
		local fail_jobdir=$fail_jobdir_base
		local -i jobdir_idx=1
		while [[ -d "$fail_jobdir" ]] ; do
		    fail_jobdir="${fail_jobdir_base}.$jobdir_idx"
		    jobdir_idx=$((jobdir_idx+1))
		done
		mv "$tmp_jobdir" "$fail_jobdir" || fatal "Can't rename $tmp_jobdir to $fail_jobdir"
	    fi
	    ((hard_fail_on_error)) && finis "Job $jobname failed, exiting!"
	fi
	# Save intermediate status in case something goes wrong.
	report_ci_results
    fi
    return $status
}

if [[ -z "${workloads[*]}" ]] ; then
    readarray -t workloads <<< "$(print_workloads)"
fi

bad_workload=0
for workload in "${workloads[@]}" ; do
    if ! get_workload "$workload" >/dev/null 2>&1; then
	bad_workload=1
	echo "Unsupported workload $workload" 1>&2
    fi
done
if ((bad_workload)) ; then
    exit 1
fi

if ((! debugonly)) ; then
    set_pin_nodes
    if ((take_prometheus_snapshot)) ; then
	start_prometheus_snapshot
    fi
    all_runtimeclasses=("${runtimeclasses[@]}")
    runtimeclasses=()
    for runtimeclass in "${all_runtimeclasses[@]}" ; do
	check_runtimeclass "$runtimeclass" && runtimeclasses+=("$runtimeclass")
    done
    starting_timestamp=$(date +%s)
    job_datestamp=$(date -u '+%Y_%m_%dT%H_%M_%S%z' --date=@"$starting_timestamp")
    artifactdir=${artifactdir//%s/$job_datestamp}
    if ((restart)) ; then
	if [[ -d "$artifactdir" ]] ; then
	    for d in "$artifactdir"/* ; do
		if [[ -d "$d" && -f "$d/clusterbuster-report.json" ]] ; then
		    uuid=$(jq -r .metadata.uuid "$d/clusterbuster-report.json")
		    break
		fi
	    done
	fi
    else
	if [[ -n "$artifactdir" && -f "$artifactdir/clusterbuster-report.json" ]] ; then
	    rm -rf "$artifactdir"
	fi
	if [[ -n "$artifactdir" && ! -d "$artifactdir" ]] ; then
	    mkdir -p "$artifactdir" || fatal "Cannot create artifact directory!"
	fi
    fi

    if [[ -n "$artifactdir" && ! -d "$artifactdir" ]] ; then
	exec > >(tee -a "$artifactdir/stdout.kata-perf-suite.log")
	exec 2> >(tee -a "$artifactdir/stderr.kata-perf-suite.log" >&2)
    fi

    if ((use_python_venv)) ; then
	python_venv=$(mktemp -d -t "cb-ci-venv.XXXXXXXX")
	python_create_venv "$python_venv"
    fi

    monitor "$run_timeout"
    trap 'if ((monitor_pid > 0)) ; then kill -9 "$monitor_pid"; monitor_pid=0; fi; timedout=1; if ((job_pid > 0)) ; then kill -TERM "$job_pid"; echo Cleaning up 1>&2 ; fi; fail=3; finis "Run timed out after $run_timeout seconds"' USR1
    trap 'if ((monitor_pid > 0)) ; then kill -9 "$monitor_pid"; monitor_pid=0; fi; interrupted=1; if ((job_pid > 0)) ; then kill -TERM "$job_pid"; echo Cleaning up 1>&2; fi; if ((fail < 2)); then fail=2; fi; finis "Run interrupted"' TERM INT HUP
    trap 'finis' EXIT
    if ((force_pull_image)) ; then
	"$__force_pull_clusterbuster_image__"
    fi
fi

if [[ -n "$prerun" && -x "$prerun" ]] ; then
    echo "Running pre-run"
    "$prerun" "$@"
fi

for workload in "${workloads[@]}" ; do
    # Use a separate counter for each workload/runtime
    counter=0
    call_api -w "$workload" test "$job_runtime"
done

if [[ -n "$postrun" && -x "$postrun" ]] ; then
    echo "Running post-run"
    "$postrun" "$@"
fi
